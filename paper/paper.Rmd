---
title: "The Hot Hand in Call of Duty Search and Destroy"
authors:
  - name: Tony ElHabr
    email: anthonyelhabr@gmail.com
    url: https://tonyelhabr.rbind.io
  - name: Andrew ElHabr
    email: andrewelhabr@gatech.edu
    affiliation: Georgia Institute of Technology
    department: School of Industrial and Systems Engineering (ISyE)
    location: Atlanta, Georgia, USA
abstract: |
  Our research investigates patterns in round win percentages in professional Search and Destroy (SnD) matches of the popular first-person shooter game Call of Duty (CoD). First, we find evidence supprting the hypothesis that round win probability can be modeled as a constant across the series, although not at the naive 50%. Second, we examine post-streak round win probability, given the series outcome. We find no evidence that post-streak win rate is significantly different than expected for combinations of streak length, series length, and series winner, suggesting that the perception of momentum at the team level is just that, perception.
bibliography: references.bib
keywords:
  - esports
  - Call of Duty
  - hot hand
  - runs test
output:
  rticles::arxiv_article:
    includes:
      in_header: preamble.tex
---

```{r}
#| label: setup
#| include: false
#| echo: false
#| eval: true
knitr::opts_chunk$set(
  eval = FALSE,
  echo = FALSE,
  include = FALSE,
  message = FALSE,
  warning = FALSE
)
```

```{r}
#| label: setup-code
library(dplyr)
library(tidyr)
library(purrr)
library(gt)
library(scales)

cod_rounds <- read_csv('data/cod_rounds.csv')
```

```{r}
#| label: descriptive-cod-snd-stats
cod_n_series <- cod_rounds |> 
  distinct(series_id) |> 
  nrow()

cod_n_rounds <- cod_rounds |> 
  distinct(series_id, round) |> 
  nrow()

cod_o_win_prop <- cod_rounds |> 
  filter(is_offense) |> 
  count(win_round) |> 
  mutate(prop = n / sum(n)) |> 
  filter(win_round) |> 
  pull(prop)
cod_o_win_prop^2 * (1 - cod_o_win_prop)
cod_o_win_prop * (1 - cod_o_win_prop)^2

cod_o_win_prop_by_game <- cod_rounds |> 
  filter(is_offense) |> 
  count(game, win_round) |> 
  group_by(game) |> 
  mutate(prop = n / sum(n)) |> 
  ungroup() |> 
  filter(win_round) |> 
  select(game, n, prop)

pull_cod_o_win_prop_by_game <- function(.game) {
  cod_o_win_prop_by_game |> 
    filter(game == .game) |> 
    pull(prop) |> 
    scales::percent(accuracy = 0.1)
}

cod_n_series_lan <- cod_rounds |> 
  filter(event |> stringr::str_detect('C[Hh][Aa][Mm][Pp]|Major')) |> 
  distinct(series_id) |> 
  nrow()

cod_win_series_prop <- cod_rounds |> 
  distinct(series_id, win_series, n_rounds) |> 
  count(n_rounds) |> 
  mutate(prop = n / sum(n)) |> 
  arrange(n_rounds)
```

# Introduction

## Call of Duty Search and Destroy

Call of Duty (CoD), first released in 2003, is one of the most popular first-person shooter (FPS) video game franchises of all-time. The most popular mode in the competitive scene is "Search and Destroy" (SnD).[^1] SnD is a one-sided game mode in which one team, the offensive side, tries to destroy one of two designated bomb sites on the map.

[^1]: SnD bears resemblance to "Bomb Defusal" in Counter-Strike and "Plant/Defuse" in Valorant, two other FPS games played in more popular professional leagues.

In professional CoD SnD, the two teams take turns playing offense and defense every round. They must win six rounds to win the series.[^2] A round can end in one of five ways:

[^2]: A maximum of 11 even rounds can be played. There is no "sudden death" or "win by two" rule like there are for SnD equivalent in professional Counter-Strike and Valorant matches.

1.  One team eliminates all members of the other team prior to a bomb plant. (Eliminating team wins.)
2.  The offensive team eliminates all members of the defensive team after a bomb plant.[^3] (Offense wins.)
3.  The defensive team defuses the bomb after a bomb plant.[^4] (Defense wins.)
4.  The offensive team does not make a plant by the time the round timer ends. (Defense wins.)

[^3]:
    -   The bomb can be picked up by any member of the offensive team.
    -   The bomb carrier is not obstructed at all by carrying the bomb (i.e. movement is the same, weapon usage is the same).
    -   The defense does not get any visual indication for who is carrying the bomb.
    -   A bomb plant takes five seconds. The timer resets if the player stops planting site prior to completing it.
    -   A bomb defuse takes seven seconds. The timer resets if the player "drops" the bomb.
    -   The bomb takes 45 seconds to defuse after being planted.

[^4]: Often the defensive team will try to eliminate all team members prior to making the defuse, but in some cases, they may try to "ninja" defuse.

We adopt the terminology "series" to refer to what CoD SnD players typically call a "match", so as to emulate the terminology of playoff series in professional leagues like the National Basketball Association, National Hockey League, and Major League Baseball. A "game" or a "match" in such leagues is analogous to a "round" of CoD SnD. Further, it is analogous to a trial in statistical analysis of Bernoulli events.

SnD is not the only game type played in competitive CoD. Teams play in a head-to-head, best-of-five (first-to-three wins) format, where SnD is always played as the second and fifth game mode (if a fifth variant is needed). The best-of-five across game types could also be called a "series", but since we analyze only the SnD game types, we refer to SnD games as series (of rounds).

Anecdotally, most observers swear by the existence of momentum in CoD SnD series, to the extent that vernacular has been developed to describe such phenomenon. People say that teams "ice up" when the team wins several consecutive rounds to come back to win a series, often culminating with a series-clinching round win.[^5] Further, viewers have come to embrace the "5-3" phenomenon, where teams win three consecutive rounds after facing a 5-3 deficit to win 6-5. There is even a term for the rare 0-5 comeback---a "full sail".

[^5]: This vernacular is not specific to CoD SnD in specific, and is not only used in the contexts of streaks.

## Data

CoD has roughly gone through three eras of professional gaming: (1) Major League Gaming (MLG) tournaments prior to 2016; (2) the CoD World League (CWL), initiated in 2016; and (3) the 12-franchise CoD League (CDL), operating since 2020. The CDL has completed three year-long "seasons" as of August 2022.[^6]

[^6]: CoD is fairly unique compared to other esports in that it runs on an annual lifecycle (released coming in the late fall), where a new game is published every year under the same title. Each new game bears resemblance to past ones, often introducing relatively small variations ("improvements") to graphics, game modes, and other facets of gameplay. During the CDL era, the games released have been Modern Warfare (2020), Cold War (2021) and Vanguard (2022).

The data set consists of all SnD matches played in major tournaments and qualifiers during the CDL era, totaling 7,792 rounds across 852 series.[^7] Data was collected in spreadsheets by community member "IOUTurtle".[^8]

[^7]: 288 of the series occur in major tournaments, which are considered to be more "competitive" than the qualifiers since they are played in person (COVID-permitting), whereas the qualifiers are played online.

[^8]: Raw data: <https://linktr.ee/CDLArchive>. Author: <https://twitter.com/IOUTurtle>. Processed data can be found at <https://github.com/tonyelhabr/fps_round_games/blob/master/data/cod_rounds.csv>.

The observed offensive round win percentage across all rounds is $\tau_O$ = 47.8%.[^9] Table \ref{tbl:cod-o-win-prop-by-series-state} shows round win percentages by series "state" (i.e. the number of round wins by each team prior to an upcoming round). Offensive round win rate is not quite constant, although never veers more than 10% from this overall average.

[^9]: Offensive round win percentage has been nearly constant across the three games during the CDL era: 1. 47.2% in MW (2020) 2. 47.9% in Cold War (2021) 3. 48.1% in Vanguard (2022)

```{r}
#| label: cod_o_win_prop
cod_round_and_series_win_prop_by_side <- cod_rounds |>
  group_by(pre_cumu_w, pre_cumu_l, is_offense) |>
  summarize(
    n = n(),
    across(c(win_round, win_series), sum)
  ) |>
  ungroup() |>
  mutate(
    win_round_prop = win_round / n,
    win_series_prop = win_series / n
  )

cod_round_and_series_win_prop_by_side |>
  filter(is_offense) |>
  transmute(
    pre_cumu_w,
    pre_cumu_l,
    lab = sprintf('%.1f%%\n(%s)', round(100 * win_round_prop, 1), n)
  ) |>
  pivot_wider(
    names_from = pre_cumu_l,
    values_from = lab
  ) |>
  arrange(pre_cumu_w) |>
  gt::gt() |>
  gt::cols_label(
    pre_cumu_w = "Defense round wins",
  ) |>
  gt::tab_spanner(
    label = "Offense round wins",
    columns = `0`:`5`
  ) |>
  gt::as_latex() |> 
  cat()
```

```{=tex}
\begin{longtable}{crrrrrr}
\caption{Offensive round win rates for the upcoming round, given both the offensive and defensive team's prior number of round wins. Numbers in parentheses are sample sizes.}\label{tbl:cod-o-win-prop-by-series-state} \\
\toprule
& \multicolumn{6}{c}{Offense round wins} \\ 
\cmidrule(lr){2-7}
Defense round wins & 0 & 1 & 2 & 3 & 4 & 5 \\ 
\midrule
0 & 47.8\%
(852) & 46.6\%
(408) & 43.1\%
(216) & 43.5\%
(115) & 43.3\%
(67) & 40.5\%
(37) \\ 
1 & 48.6\%
(444) & 49.3\%
(418) & 51.5\%
(309) & 43.4\%
(205) & 43.3\%
(120) & 39.4\%
(99) \\ 
2 & 52.8\%
(218) & 48.9\%
(305) & 48.9\%
(315) & 46.6\%
(262) & 48.7\%
(189) & 42.1\%
(133) \\ 
3 & 54.5\%
(123) & 46.0\%
(200) & 49.6\%
(250) & 45.6\%
(248) & 44.4\%
(214) & 44.8\%
(174) \\ 
4 & 56.9\%
(65) & 54.5\%
(145) & 47.2\%
(193) & 44.7\%
(228) & 55.2\%
(221) & 50.5\%
(208) \\ 
5 & 47.4\%
(38) & 49.4\%
(83) & 47.1\%
(136) & 50.9\%
(175) & 45.2\%
(177) & 46.0\%
(202) \\ 
\bottomrule
\end{longtable}
```
On the extremes, 6-0 sweeps make up 4.7% of all series, while 6-5 series make up 23.7 of series.

At tournaments, higher-seeded ("better") teams choose whether they want to start on offense in the SnD series played as the second game or the fifth game, and their opponent is assigned to play offense in the first round of the SnD slot not chosen.[^10][^11] [@codrules] With online qualifiers, teams all play each other twice throughout the season. Each team gets to play the higher-seeded role once in their matchups, despite their win-loss records. Overall, we might say that bias due to stronger teams playing defense (slightly advantageous) more often is very minimal.

[^10]: "Hardpoint" has been played as the first and fourth games in a matchup; the variant for the third game was Domination in the 2020 season, and Control in the 2021 and 2022 seasons.

[^11]: Anecdotally, the higher-seeded teams tend to choose to play defense in the first round of the SnD series played as the second game, although this choice is not consistent across teams, or with the same team over time.

# Literature review

There have been a handful of studies of the distribution of games played in a series of a professional sport. Most assume a constant probability $\phi$ of a given team winning a game in the series, regardless of the series state. Mosteller [-@mosteller1952] observed that the American League had dominated the National League in Major League Baseball's (MLB) World Series matchups, implying that games should not be modeled with a constant (null) $\phi_0 = 0.5$. Mosteller proposed three approaches for identifying the optimal constant probability value of the stronger team in the World Series, finding $\phi \approx 0.65$ in each case: (1) solving for $\phi$ from the observed average number of games won by the loser of the series, which he called the "method of moments" approach; (2) maximizing the likelihood that the sample would have been drawn from a population in which the probability of a team winning a game is constant across the series (i.e. maximum likelihood), and (3) minimizing the chi-square goodness of fit statistic $\chi^2$ for $\phi$.

Chance [-@chance2020] re-examines the constant probability notion in Major League Baseball's (MLB) World Series (1923--2018), the National Basketball Association's (NBA) Finals (1951--2018), and the National Hockey League's (NHL) Stanley Cup (1939--2018). Chance finds strong evidence against the null hypothesis of $\phi_0 = 0.5$ in the MLB and NHL championship series when applying Mosteller's first and second methods. Chance goes on to outline a conditional probability framework (likelihood of winning a game given the series state) which can exactly explain the distribution of the number of games played.

Momentum, one of most discussed topics in sports analytics, goes hand-in-hand with a discussion of the nature of series outcomes.[^12] Two opposing fallacies are observed in the context of momentum: the "gambler's fallacy" (negative recency) and the "hot hand fallacy" (positive recency). Per Ayton et al. [-@ayton2004], negative recency is "the belief that, for random events, runs of a particular outcome ... will be balanced by a tendency for the opposite outcome", while positive recency is the expectation of observing future results that match recent results.

[^12]: We often use use "streaks" and momentum interchangeably, but as [@steeger2021] note, momentum implies dependence between events, whereas streaking does not.

Studying both player streaks and team streaks in basketball, in both observational and controlled settings. Gilovich et al. [-@gilovich1985], henceforth GVT, do not find evidence for the hot hand phenomenon. However, Miller and Sanjurjo [-@miller2018], henceforth MS, provide a framework for quantifying streak selection bias, which effectively works in the manner posited by the gambler's fallacy. Specifically, MS say that a "bias exists in a common measure of the conditional dependence of present outcomes on streaks of past outcomes in sequential data" implying that, under i.i.d. conditions, "the proportion of successes among the outcomes that immediately follow a streak of consecutive successes is expected to be strictly less than the underlying (conditional) probability of success". When applying streak selection bias to GVT's data, MS come to the opposite conclusions as GVT.

Other research has borrowed a common approach from the field of quality control, looking at unlikely sequences of events with the Wald-Wolfowitz runs test [@peel2015], [@steeger2021]. Peel and Clauset find no evidence for unlikely sequences of scoring events in the NHL, College Football (CFB), and National Football League (NFL), but do in the NBA. As a check on their entropy approach to momentum identification, Steeger et al. found three NHL teams who sequence of wins in the 2018-2019 regular season violated the Wald-Wolfowitz null hypothesis, although these teams did not match the teams identified with their primary approach.

## Our contribution

Despite the plethora of existing research on games played in a series and momentum in sports, these topics have yet to be investigated heavily, if at all, in esports. Work has been done to examine intra-round win probability in other FPS titles such as Counter-Strike [@xenopoulos2022] and Valorant [@derover2021], both of which are round-based like CoD SnD. However, considering Counter-Strike and Valorant specifically, research on round-level trends seems non-existant, perhaps for one of many reasons:

1.  Both have economic aspects that can create clear advantages for one side in a given round, given how prior rounds played out. CoD has no such equivalent, except for perhaps "kill streaks", which infrequently play a role.
2.  Teams play either offense or defense for many consecutive rounds. (The former has a 14-14-1 format and the latter uses a 12-12-1 format.) On the other hand, teams in CoD SnD rotate roles every round, analogous to a 1-1-1-1-1-1-1 format for home advantage in best-of-seven series for professional sports like the MLB, NBA, and NHL.[^13] While theoretically one might be able to account for any kind of format, such as a 5-5-1, the rotation of team sides every round is convenient for convincing ourselves that rounds could reasonably be modeled as i.i.d. Bernoulli trials.
3.  Both Counter-Strike and Valorant have overtime rules---team must win by two rounds---which can make end-of-series sequences difficult to model. CoD SnD does not have overtime rules.

[^13]: 1-1-1-1-1-1-1 is not used today in these leagues, but it was at least once in each league.

To our knowledge, there is no existing public statistical research on CoD SnD format, beyond descriptive analysis on social media. While intra-round trends may be more directly applicable to teams looking for an advantage on their competition, broader investigation on a common concept like the hot-hand phenomenon in a new field---particularly one that is less subjected to factors that may be difficult to control for, e.g. weather---should be useful as a precedent or supplement for future researchers.

# Methodology

## Distribution of rounds played

In a best-of-$s$ format, assuming a constant round win probability $\phi$ ($0 \leq \phi \leq 1$) for one team[^14], the probability that a series ends in $r$ rounds ($r \leq s$), $\hat{\Phi}(r)$ is

[^14]: If $\phi > 0.5$, we can say that this is the stronger team.

```{=tex}
\begin{equation}\label{eq:m}
m = \frac{s + 1}{2}
\end{equation}
```
```{=tex}
\begin{equation}\label{eq:series-length}
\hat{\Phi}(r) = \frac{(r - 1)!}{(m - 1)!(s - r)!}(\phi^{m}(1 - \phi)^{r - m} + \phi^{r - m}(1 - \phi)^m)
\end{equation}
```
$s = 11$ rounds for CoD SnD.[^15] For example, assuming $\phi = 0.5$, the probability of a series ending in 9 rounds in CoD is

[^15]: $\phi$ and other symbols are selected so as to reserve symbols like $p$ for usage in other contexts without causing confusion for the reader. Upper-case symbol, e.g. $\Phi$, are consistently used in this paper to represent proportions, while lower-case symbols are used to represent Bernoulli trials success probability. "Hats", e.g. $\hat{\Phi}$, are used to convey expectations, while bare symbols symbols convey observational data.

$$
\hat{\Phi}(9) = \frac{(9 - 1)!}{(6 - 1)!(11 - 9)!}(0.5^{6}(1 - 0.5)^{9 - 6} + 0.5^{9 - 6}(1 - 0.5)^6) = 56 (0.5^9 + 0.5^9) = 0.21875.
$$

To evaluate the constant round win probability null hypothesis---that is, that the expected and observed round win rates, $\hat{\Phi}(r)$ and $\Phi(r)$ respectively, are equal to one another---we can compute the chi-square goodness of fit statistic

```{=tex}
\begin{equation}\label{eq:chi-squ}
\chi^2 = \sum^{r \in R} \frac{(\Phi(r) - \hat{\Phi}(r))^2}{\hat{\Phi}(r)}.
\end{equation}
```
in which $R = [6, 7, 8, 9, 10, 11]$ for CoD SnD.

## Momentum

### MS post-streak probability

Let us now consider round win rate immediately following a streak of $k$ wins, given that the series lasts $r$ rounds. Removing our knowledge of a streak, we might model the Bernoulli round win probability as

```{=tex}
\begin{equation}\label{eq:pwr}
p_0(\text{win} | r) = p^{+|r}_0 = \begin{cases} 
\frac{m}{r} & \text{team wins series} \\ 
\frac{r - m}{r} & \text{team loses series}  
\end{cases}
\end{equation}
```
using $m$ from Equation \ref{eq:m}.

As shown by MS with their Theorem 1, we should expect the proportion of rounds wins immediately following a streak of $k$ rounds wins for a series lasting $r$ rounds, $\hat{P}^{+|k,r}_{MS}$, to be strictly less than $p^{+|r}$.[^16] Unfortunately, there does not exist a closed form representation for the expected value of $\hat{P}^{+|k,r}_{MS}$ for $k > 1$. Nonetheless, one may recursively build a collection of dictionaries to compute the expectation analytically, or, more conveniently, one may run simulations to estimate the expected value, as We choose to do.[^17]

[^16]: See Appendix E.1 of MS for the proof.

[^17]: We have adapted the code from Vafa [-@vafa2017], which implements MS's framework [-@miller2018].

Although it would be convenient to emulate the hypothesis testing for difference of proportions performed by MS (and GVT), our context is fundamentally different from that of MS, who focus on longitudinal data in controlled settings.[^18] The number of trials is fixed in their experimental designs, but in CoD SnD, the number of rounds played is determined as a function of the max number of possible rounds ($s$) and whether or not the team wins the series. The Bernoulli trial success probability, i.e. a round win in CoD SnD, is not independent of the opponent. Consequently, a statistical test of the difference in $\hat{P}^{+|k,r}$ and $\hat{P}^{-|kr}$, as performed by MS to evaluate their hypothesis regarding post-streak success rates, is not completely appropriate, although useful as a reference.

[^18]: GVT also performs statistical tests on shots from players in live games, i.e. "observational" data, but they note that their findings are likely affected player shot selection in the face of defensive strategy by the opposing team.

### "Notional" post-streak probability

One can consider another form of the expected proportion of rounds won immediately after a streak of $k$ round wins in a best-of-$s$ series given the length of the series ($r$ rounds), the "notional" proportion $\hat{P}^{+|k,r}_0$. The Bernoulli round win probability underlying $\hat{P}^{+|k,r}_0$ is

```{=tex}
\begin{equation}\label{eq:pwkr}
p_0(\text{win} | k, r) = p^{+|k,r}_0 = \begin{cases}
\frac{m - k}{r - k} & \text{team wins series} \\
\frac{s - m - k}{r - k} & \text{team loses series}
\end{cases}
\end{equation}
```
using $m$ from Equation \ref{eq:m}.

We can perform a binomial test to evaluate the null hypothesis $\omega = \omega_0$ for the observed probability of success $\omega$ and a user-specified $\omega_0$, where $0 \leq \omega_0 \leq 1$.[^19] If there are $r^+$ observed successes in a sample of $r$ trials and we expect that there should be $r * \omega_0$, the probability of arriving at this expected number of successes is

[^19]: $\omega$ and other symbols are chosen so as to not conflict with symbols already used elsewhere for in other equations, either generic or for CoD SnD specifically.

```{=tex}
\begin{equation}\label{eq:binom}
\Pr(r^w) = {\binom {r}{r^+}} \omega^{r^+}(1-\omega)^{r-r^+}.
\end{equation}
```
Treating the notional proportion $p^{+|k,r}_0$ as the null $\omega_0$ and plugging in the observed proportion $P^{+|k,r}$ for $\omega$ in Equation \ref{eq:binom} (treating proportions as probabilities), we can evaluate the null hypothesis that the observed probability is equal to the notional probability. If we can reject this null hypothesis, then we can consider team momentum, represented by post-streak success, plausible.

One can perform the same binomial test for the MS's streak-selection-adjusted proportion, $\hat{P}^{+|k,r}_{MS}$. FOOTY: Given the caveats mentioned before, the results should be heeded with caution.

We can further decompose Equation \ref{eq:pwkr} by the round $i$ ($i \leq r$) in which the streak of length $k$ carries into.

```{=tex}
\begin{equation}\protect\hypertarget{eq:pwkri}{}{
p_0(\text{win} | k, r, i) = p^{+|k,r,i}_0 =\{
\begin{array}{cl}
\frac{m - k}{r - k}, & \text{team wins series}, i \neq r \\
1, & \text{team wins series}, i = r \\
\frac{s - m - k}{r - k}, & \text{team loses series}, i \neq r \\
0, & \text{team loses series}, i = r
\end{array}
}
\label{eq:pwkri}
\end{equation}
```
Again, one might apply a binomial test to evaluate the hypothesis that the expected proportions, both $\hat{P}^{+|k,r,i}_0$ and $\hat{P}^{+|k,r,i}_{MS}$, are equal to the observed proportion $P^{+|k,r}$.

### Wald-Wolfowitz runs test

Stepping back from the one-sided perspective of a single team's round win probability when streaking, one can attempt to detect the hot hand phenomenon with the Wald-Wolfowitz runs test. Under the null hypothesis, the number of runs in a sequence of $r$ trials, $\zeta(r)$, is a random variable that can take on values $r^+$ and $r^-$ for success and failure respectively, with the following mean $\mu$ and variance $\sigma^2$.

```{=tex}
\begin{equation}\protect\hypertarget{eq:ww}{}{
\mu = \frac{2r^{+}r^{-}}{r} + 1, \sigma^2 = \frac{(\mu-1)(\mu-2)}{r-1}
}\label{eq:ww}\end{equation}
```
To incorporate our findings regarding constant round win probability, We can specify that $\Pr(r^+) = \phi$ (and, conversely, that $\Pr(r^-) = 1 - \phi$).

One can subset the observed series sequences to those that violate the run test null hypothesis and perform a test of proportions, where the null is that the observed rate $\psi^+$ of such series is equal to the frequency rate $\psi_0$. The test statistic $Z$

```{=tex}
\begin{equation}\protect\hypertarget{eq:prop}{}{
Z = \frac{\psi^+ - \psi^+_0}{\sqrt{\psi^+_d (1 - \psi^+_d) ( \frac{1}{N^+} + \frac{1}{\hat{N}^+})}}
}\label{eq:prop}\end{equation}
```
where $\psi^+_d = \frac{r^+ - \hat{r}^+}{N^+ - \hat{N}^+}$. If we can reject the null hypothesis for many sequences, then there is implicit evidence in favor of the hot hand.

# Results

First, We investigate the constant probability assumption and the distribution of rounds played in a series. Chance's [-@chance2020] work is closely related to mine, and, in fact, provides a guide for this investigation. Afterwards, We investigate post-streak win rates within the context of momentum.

## Distribution of rounds played

Using Equation \ref{eq:chi-squ}, We find that $\chi^2 = 16.0$ ($p$-value of 0.0068) for the naive constant round win probability $\phi_0 = 0.5$. Thus, We can comfortably reject the constant probability hypothesis for the null $\phi_0 = 0.5$, even at a confidence level of $\alpha = 0.01$.

```{r}
#| label: cod_series_outcome_prop
.max_round <- 11
.cutoff <- 6
prob_of_series_lasting_r_rounds <- function(r, p = 0.5, s) {
  m <- as.integer((s + 1) / 2)
  (factorial(r - 1) / (factorial(m - 1) * factorial(r - m))) * (p^m * (1 - p)^(r - m) + p^(r - m) * (1 - p)^m)
}

expected_series_streaks_of_outcomes <- function(m, n) {
  factorial(m + n) / (factorial(m) * factorial(n))
}

# https://raw.githubusercontent.com/dgrtwo/splittestr/master/R/vectorized-prop-test.R
vectorized_prop_test_approx <- function(a, b, c, d) {
  n1 <- a + b
  n2 <- c + d
  n <- n1 + n2
  p <- (a + c) / n
  E <- cbind(p * n1, (1 - p) * n1, p * n2, (1 - p) * n2)
  
  x <- cbind(a, b, c, d)
  
  DELTA <- a / n1 - c / n2
  YATES <- pmin(.5, abs(DELTA) / sum(1 / n1 + 1 / n2))
  
  STATISTIC <- rowSums((abs(x - E) - YATES)^2 / E)
  PVAL <- pchisq(STATISTIC, 1, lower.tail = FALSE)
  PVAL
}

vectorized_prop_test_exact <- function(a, b, c, d) {
  sapply(seq_along(a), function(i) {
    fisher.test(cbind(c(a[i], c[i]), c(b[i], d[i])))$p.value
  })
}

vectorized_prop_test <- function(x1, n1, x2, n2, conf.level = 0.95) {
  a <- x1
  b <- n1 - x1
  c <- x2
  d <- n2 - x2
  
  # if any values are < 20, use Fisher's exact test
  exact <- (a < 20 | b < 20 | c < 20 | d < 20)
  
  pvalue <- rep(NA, length(a))
  
  if (any(exact)) {
    pvalue[exact] <- vectorized_prop_test_exact(a[exact], b[exact], c[exact], d[exact])
  }
  if (any(!exact)) {
    pvalue[!exact] <- vectorized_prop_test_approx(a[!exact], b[!exact], c[!exact], d[!exact])
  }
  
  mu1 <- a / (a + b)
  mu2 <- c / (c + d)
  
  ## confidence interval
  alpha2 <- (1 - conf.level) / 2
  DELTA <- mu2 - mu1
  WIDTH <- qnorm(alpha2)
  alpha <- (a + .5) / (a + b + 1)
  beta <- (c + .5) / (c + d + 1)
  
  n <- n1 + n2
  YATES <- pmin(.5, abs(DELTA) / sum(1 / n1 + 1 / n2))
  
  z <- qnorm((1 + conf.level) / 2)
  WIDTH <- z * sqrt(mu1 * (1 - mu1) / n1 + mu2 * (1 - mu2) / n2)
  
  tibble(
    estimate = DELTA,
    conf.low = pmax(DELTA - WIDTH, -1),
    conf.high = pmin(DELTA + WIDTH, 1),
    p.value = pvalue
  )
}

cod_actual_round_streaks <- cod_rounds |> 
  filter(round <= .max_round) |> 
  filter(win_series) |> 
  mutate(across(win_round, as.integer)) |> 
  group_by(series_id) |> 
  summarize(
    wins = max(cumu_w),
    losses = max(cumu_l),
    ws = paste0(win_round, collapse = '-')
  ) |> 
  ungroup() |> 
  mutate(n_rounds = wins + losses) |> 
  unite(
    record, wins, losses, sep = '-'
  ) |>
  count(record, n_rounds, ws, sort = TRUE) |> 
  mutate(prop = n / sum(n))

summarize_cod_streaks <- function(p = 0.5) {
  
  expected_round_streaks <- tibble(
    n_rounds = .cutoff:.max_round
  ) |> 
    mutate(
      series_prop = map_dbl(n_rounds, ~prob_of_series_lasting_r_rounds(.x, s = .max_round, p = !!p)),
      n_expected_series_streaks = map_dbl(n_rounds, ~expected_series_streaks_of_outcomes(.cutoff, .x - .cutoff))
    ) |> 
    transmute(
      n_rounds,
      series_prop,
      prop = series_prop / n_expected_series_streaks
    )
  
  round_streaks <- full_join(
    cod_actual_round_streaks |> 
      rename_with(~sprintf('%s_actual', .x), c(n, prop)),
    expected_round_streaks |> 
      rename_with(~sprintf('%s_expected', .x), prop),
    by = 'n_rounds'
  )
  
  round_streak_prop <- round_streaks |> 
    drop_na() |> 
    mutate(
      prop_diff = prop_actual - prop_expected,
      total_actual = sum(n_actual),
      n_expected = round(prop_expected * total_actual),
      p = vectorized_prop_test(n_actual, total_actual, n_expected, total_actual)
    ) |> 
    select(-total_actual) |> 
    unnest_wider(p) |> 
    arrange(p.value)
  
  series_outcomes <- full_join(
    cod_actual_round_streaks |> 
      group_by(record, n_rounds) |> 
      summarize(
        across(n, sum)
      ) |> 
      ungroup() |> 
      mutate(prop = n / sum(n)) |> 
      rename_with(~sprintf('%s_actual', .x), c(n, prop)),
    expected_round_streaks |> 
      select(n_rounds, prop_expected = series_prop),
    by = 'n_rounds'
  )
  
  series_outcome_prop <- series_outcomes |> 
    drop_na() |> 
    mutate(
      prop_diff = prop_actual - prop_expected,
      total_actual = sum(n_actual),
      n_expected = round(prop_expected * total_actual),
      p = vectorized_prop_test(n_actual, total_actual, n_expected, total_actual)
    ) |> 
    select(-total_actual) |> 
    unnest_wider(p) |> 
    arrange(p.value)
  
  list(
    rounds = round_streak_prop,
    series = series_outcome_prop
  )
}

cod_streaks_naive_res <- summarize_cod_streaks(p = 0.5)
```

Table \ref{tbl:cod-prob-series-lasting-r-rounds} shows the expected series lasting $r$ rounds, $\hat{\Phi}_0(r)$ (under the assumption $\phi_0 = 0.5$), for $s = 11$, along with the observed proportions, $\Phi(r)$, in CoD SnD.

```{=tex}
\begin{longtable}{rrrr}
\caption{The expected proportion of series lasting $r$ rounds ($\hat{\Phi}_0(r)$) in a best-of-11 format, where $r \in R = [6, 7, 8, 9, 10, 11]$ under the assumption that each team has a constant round win probability $\phi_0 = 0.5$. The observed frequencies for CoD SnD are shown as a count $N(r)$ and as a proportion $\Phi(r)$ of all series ($\sum^{r \in R} N(r)$).}\label{tbl:cod-prob-series-lasting-r-rounds} \\
\toprule
$r$ & $N(r)$ & $\Phi(r)$ & $\hat{\Phi}_0(r)$ \\ 
\midrule
6 & 40 & $4.7\%$ & $3.1\%$ \\ 
7 & 101 & $11.9\%$ & $9.4\%$ \\ 
8 & 141 & $16.5\%$ & $16.4\%$ \\ 
9 & 185 & $21.7\%$ & $21.9\%$ \\ 
10 & 183 & $21.5\%$ & $24.6\%$ \\ 
11 & 202 & $23.7\%$ & $24.6\%$ \\ 
\bottomrule
\end{longtable}
```
```{r}
#| label: cod_series_outcomes_naive_chi
generate_chi_label <- function(statistic, p.value) {
  sprintf('%.1f (%s)', statistic, ifelse(p.value <= 0.01, '<=0.01', as.character(round(p.value, 2))))
}

perform_series_chi_test <- function(series) {
  chisq.test(
    series$n_actual, 
    p = series$prop_expected
  ) |> 
    broom::tidy()
}

cod_series_outcomes_naive_chi <- cod_streaks_naive_res$series |> 
  perform_series_chi_test()
```

```{r}
#| label: cod-alternative-to-p=0.5-method-prep
min_p1 <- 0.5
max_p1 <- 0.7
interval_p1 <- 0.0025
cod_ps <- tibble(p = seq(min_p1, max_p1, by = 0.0025))
```

```{r}
#| label: cod-alternative-to-p=0.5-method-1
## p. 365 on https://math.mit.edu/classes/18.095/2016IAP/lec9/Sports_Mosteller1952_WorldSeries.pdf
cod_prob_of_series_lasting_r_rounds <- function(r, p) {
  prob_of_series_lasting_r_rounds(r = r, p = p, s = 11)
}

theoretical_cod_series_length <- function(p) {
  6 * cod_prob_of_series_lasting_r_rounds(r = 6, p = p) +
    7 * cod_prob_of_series_lasting_r_rounds(r = 7, p = p) +
    8 * cod_prob_of_series_lasting_r_rounds(r = 8, p = p) +
    9 * cod_prob_of_series_lasting_r_rounds(r = 9, p = p) +
    10 * cod_prob_of_series_lasting_r_rounds(r = 10, p = p) +
    11 * cod_prob_of_series_lasting_r_rounds(r = 11, p = p)
}

cod_rounds_per_series <- cod_streaks_naive_res$series |>
  summarize(
    actual = sum(n_rounds * prop_actual),
    expected = sum(n_rounds * prop_expected)
  )

cod_theoretical_series_lengths1 <- cod_ps |>
  mutate(
    theoretical_series_length = map_dbl(p, theoretical_cod_series_length),
    diff = theoretical_series_length - cod_rounds_per_series$actual
  )

cod_theoretical_p1 <- cod_theoretical_series_lengths1 |>
  slice_min(abs(diff), n = 1) |>
  pull(p)
```

```{r}
#| label: cod-alternative-to-p=0.5-method-2
pluck_cod_n <- function(.n_rounds) {
  cod_streaks_naive_res$series |>
    filter(n_rounds == .n_rounds) |>
    pull(n_actual)
}

cod_n6 <- pluck_cod_n(6)
cod_n7 <- pluck_cod_n(7)
cod_n8 <- pluck_cod_n(8)
cod_n9 <- pluck_cod_n(9)
cod_n10 <- pluck_cod_n(10)
cod_n11 <- pluck_cod_n(11)

## This adjustment is something that is not done in the paper. We do it here to reduce
##   the magnitude of the exponents.
cod_pm <- pmin(cod_n6, cod_n7, cod_n8, cod_n9, cod_n10, cod_n11)
cod_n6adj <- round(10 * cod_n6 / cod_pm)
cod_n7adj <- round(10 * cod_n7 / cod_pm)
cod_n8adj <- round(10 * cod_n8 / cod_pm)
cod_n9adj <- round(10 * cod_n9 / cod_pm)
cod_n10adj <- round(10 * cod_n10 / cod_pm)
cod_n11adj <- round(10 * cod_n11 / cod_pm)

maximize_cod_series_p <- function(p) {
  cod_prob_of_series_lasting_r_rounds(r = 6, p = p)^cod_n6adj *
    cod_prob_of_series_lasting_r_rounds(r = 7, p = p)^cod_n7adj *
    cod_prob_of_series_lasting_r_rounds(r = 8, p = p)^cod_n8adj *
    cod_prob_of_series_lasting_r_rounds(r = 9, p = p)^cod_n9adj *
    cod_prob_of_series_lasting_r_rounds(r = 10, p = p)^cod_n10adj *
    cod_prob_of_series_lasting_r_rounds(r = 11, p = p)^cod_n11adj
}

cod_theoretical_series_lengths2 <- cod_ps |>
  mutate(
    theoretical_series_length = map_dbl(p, maximize_cod_series_p)
  )

cod_theoretical_p2 <- cod_theoretical_series_lengths2 |>
  slice_max(theoretical_series_length, n = 1) |>
  pull(p)
```

```{r}
#| label: cod-alternative-to-p=0.5-method-3
summarize_cod_series_chi <- function(p) {
  summarize_cod_streaks(p) |> 
    pluck('series') |> 
    perform_series_chi_test()
}

cod_theoretical_series_lengths3 <- cod_ps |> 
  filter(p >= 0.56, p < 0.585) |> 
  mutate(
    chi_squ = map_dbl(
      p,
      ~summarize_cod_series_chi(.x) |> 
        pluck('statistic')
    )
  )

cod_theoretical_p3 <- cod_theoretical_series_lengths3 |> 
  slice_min(chi_squ, n = 1) |> 
  pull(p)
```

```{r}
#| label: cod-alternatives-to-p=0.5
cod_streaks_other_res <- tibble(
  p = c(0.5, cod_theoretical_p1, cod_theoretical_p2, cod_theoretical_p3),
  idx = 0L:3L,
  name = c('0. Naive', '1. Method of moments', '2. Maximum likelihood', '3. Minimum Chi-square')
) |> 
  mutate(
    series_streaks = map(
      p,
      ~summarize_cod_streaks(.x) |> 
        pluck('series') 
    ),
    chi_squ = map(
      series_streaks,
      ~.x |> 
        perform_series_chi_test() |> 
        select(statistic, p.value)
    )
  )
```

Table \ref{tbl:mosteller-methods-results} shows the alternate values for the constant round win probability that We find when applying the three methods suggested by Mosteller [-@mosteller1952]. Each is approximately or equal to 0.575, and, when applying Equation \ref{eq:chi-squ}, each results in a $\chi^2$ value for which We cannot reject the constant probability null hypothesis.

```{=tex}
\begin{longtable}[]{@{}lrr@{}}
\caption{Alternate estimates of the constant probability ($\phi$) for winning a given round in a CoD SnD, applying the three methods suggested by Mosteller (1952), in addition to the naive ($\phi_0 = 0.5$).}\label{tbl:mosteller-methods-results} \\
\toprule()
Method & $\phi$ & $\chi^2$ (p-value) \\
\midrule()
\endfirsthead
\toprule()
Method & $\phi(r)$ & $\chi^2$ (p-value) \\
\midrule()
\endhead
0. Naive & 0.5000 & 16.0 ($\leq$ 0.01) \\
1. Method of moments & 0.5725 & 3.6 (0.6) \\
2. Maximum likelihood & 0.5750 & 3.5 (0.62) \\
3. Minimum ($\chi^2$) & 0.5775 & 3.5 (0.62) \\
\bottomrule()
\end{longtable}
```
Table \ref{tbl:expected-series-lengths-alternative-ps} shows the new $\hat{\Phi}(r)$ when re-applying Equation \ref{eq:series-length} for the maximum likelihood estimate $\phi_2 = 0.575$, resulting in a new set of expected proportions of series lasting $r$ rounds $\hat{\Phi}_2(r)$.[^20] We observe that $\hat{\Phi}_2(r)$ is larger than $\hat{\Phi}_0(r)$ for $r \in [6, 7]$, more closely matching $\Phi(r)$. $\hat{\Phi}_2(r)$ is also closer to the observed $\Phi(r)$ for $r \in [9, 10]$, although not for $r \in [8, 11]$.

[^20]: The method of moments and minimum $\chi^2$ estimates for $\phi$ are omitted simply because the results would be nearly identical to those for the maximum likelihood estimate of $\phi$ (since they are all $\approx 0.575$).

```{=tex}
\begin{longtable}[]{@{}rrrr@{}}
\caption{The observed proportion of series $\Phi(r)$ ending in $r$ rounds in CoD SnD's best-of-11 format, compared to the expected proportion $\hat{\Phi}_0(r)$ the naive assumption $\phi_0 = 0.5$ and the expected proportion $\hat{\Phi}_2(r)$ under the maximum likelihood estimate $\phi_2 = 0.575$ for constant round win probability.}\label{tbl:expected-series-lengths-alternative-ps} \\
\toprule()
$r$ & $\Phi(r)$ & $\hat{\Phi}_0(r)$ = 0.5 & $\hat{\Phi}_2(r)$ = 0.575 \\
\midrule()
\endhead
6 & 4.7\% & 3.1\% & 4.2\% \\
7 & 11.9\% & 9.4\% & 11.2\% \\
8 & 16.5\% & 16.4\% & 17.8\% \\
9 & 21.7\% & 21.9\% & 21.8\% \\
10 & 21.5\% & 24.6\% & 23.0\% \\
11 & 23.7\% & 24.6\% & 22.0\% \\
\bottomrule()
\end{longtable}
```
Observing that $\hat{\Phi}_2(r)$ reasonably matches $\Phi(r)$ (especially in comparison to $\hat{\Phi}_0(r)$), along with the null hypothesis rejection shown in Table \ref{tbl:mosteller-methods-results}, it is fair to conclude that the constant round win probability assumption can be valid in CoD SnD series with the appropriate choice of $\phi$ ($\approx 0.575$).

## Momentum

### Post-streak probability

```{r}
#| label: cod_round_win_prop_after_k_wins
## http://keyonvafa.com/hot-hand/
get_post_streak_prob <- function(n, k, p = 0.5) {
  tosses <- rbinom(n, 1, p)
  runs <- rle(tosses)
  n_neg_after <- length(which(runs$values == 1 & runs$lengths >= k))
  n_pos_after <- sum(runs$lengths[which(runs$values == 1 & runs$lengths >= k)] - k)
  
  ## edge case
  if (n %in% cumsum(runs$lengths)[which(runs$values == 1 & runs$lengths >= k)]) {
    n_neg_after <- n_neg_after - 1
  }
  
  n_pos_after / (n_pos_after + n_neg_after)
}

simulate_post_streak_prob <- function(sims = 10000, seed = 42, ...) {
  withr::local_seed(seed)
  rerun(
    sims,
    get_post_streak_prob(...)
  ) |> 
    flatten_dbl() |> 
    mean(na.rm = TRUE)
}

vectorized_binom_test <- function(x, n, p, ...) {
  map_dfr(
    seq_along(x), 
    function(i) {
      res <- binom.test(x[i], n[i], p = p[i], ...)
      tibble(
        estimate = res$estimate,
        conf.low = res$conf.int[[1]],
        conf.high = res$conf.int[[2]],
        p.value = res$p.value
      )
    }
  )
}

cod_round_streaks <- cod_rounds |> 
  group_by(series_id, team) |> 
  mutate(
    won_prior_round1 = lag(win_round, n = 1, default = NA),
    won_prior_round2 = lag(win_round, n = 2, default = NA),
    won_prior_round3 = lag(win_round, n = 3, default = NA),
    won_prior_round4 = lag(win_round, n = 4, default = NA),
    won_prior_round5 = lag(win_round, n = 5, default = NA)
  ) |> 
  ungroup() |>
  select(
    series_id,
    team,
    is_offense,
    round,
    n_rounds,
    win_series,
    win_round,
    starts_with('won_prior_round')
  )

postprocess_round_streaks <- function(k, probs_nx_k, ...) {
  
  cols <- sprintf('won_prior_round%d', 2:k)
  col_syms <- syms(cols)
  cod_round_streaks_after_x <- cod_round_streaks |> 
    drop_na(!!!col_syms) |> 
    count(n_rounds, win_series, ..., win_round, won_prior_round1, !!!col_syms, sort = TRUE)
  
  cod_round_win_prop_after_z <- cod_round_streaks_after_x |> 
    filter(won_prior_round1, !!!col_syms)
  
  suppressMessages(
    cod_round_win_prop_after_z_with_probs <- cod_round_win_prop_after_z |> 
      group_by(win_series, n_rounds, ...) |> 
      mutate(
        total = sum(n),
        prop = n / total
      ) |> 
      ungroup() |> 
      select(n_rounds, win_round, win_series, ..., n, total, prop) |> 
      # filter(!win_round) |> 
      arrange(n_rounds, win_round, ...) |> 
      inner_join(
        probs_nx_k
      )
  )
  
  cod_round_win_prop_after_z_with_probs |> 
    mutate(
      notional_p_value = vectorized_binom_test(n, total, p = notional_prop)$p.value,
      ms_p_value = vectorized_binom_test(n, total, p = ms_prop)$p.value
    )
}

compute_probs_nx_k <- function(df, k) {
  df |> 
    mutate(
      is_valid = case_when(
        win_series ~ TRUE,
        (n_rounds - !!k - 6L) >= 0L ~ TRUE,
        TRUE ~ FALSE
      )
    ) |> 
    filter(is_valid) |> 
    select(-is_valid) |> 
    mutate(
      naive_prop = ifelse(win_series, 6L / n_rounds, (n_rounds - 6L) / n_rounds),
      notional_prop = (ifelse(win_series, 6L, n_rounds - 6L) - k) / (n_rounds - k),
      across(c(naive_prop, notional_prop), ~ifelse(win_round, .x, 1 - .x)),
      ms_prop = map2_dbl(
        n_rounds, naive_prop, 
        ~simulate_post_streak_prob(n = ..1, k = !!k, p = ..2)
      ),
      across(
        ms_prop,
        ~ifelse(win_round, .x, naive_prop + (naive_prop - .x))
      ),
      across(
        ms_prop,
        ~ifelse(is.nan(ms_prop), naive_prop, .x)
      )
    )
}

summarize_cod_win_prop_after_k_wins <- function(k) {
  probs_nx_k <- crossing(
    n_rounds = 7L:11L,
    win_series = c(TRUE, FALSE),
    win_round = c(TRUE, FALSE)
  ) |> 
    compute_probs_nx_k(k)
  
  postprocess_round_streaks(
    k = k,
    probs_nx_k = probs_nx_k
  )
}

cod_round_win_prop_after_k_wins <- tibble(win_streak = 2L:5L) |>
  mutate(
    data = map(win_streak, summarize_cod_win_prop_after_k_wins)
  ) |>
  unnest(data)
cod_round_win_prop_after_k_wins |> filter(win_round, notional_p_value < 0.05)
cod_round_win_prop_after_k_wins |> filter(win_round, ms_p_value < 0.05)
```

```{r}
#| label: cod_round_win_prop_after_k_wins-table
cod_round_win_prop_after_k_wins |> 
  mutate(
    orig_notional_p_value = notional_p_value,
    orig_ms_p_value = ms_p_value
  ) |> 
  # group_by(win_streak) |> 
  mutate(
    across(c(notional_p_value, ms_p_value), ~p.adjust(.x, method = 'BY'))
  ) |> 
  # ungroup() |>
  filter(win_streak == 3L) |> 
  # filter(ms_p_value < 0.05)
  mutate(
    prop_lab = scales::percent(prop, accuracy = 0.1),
    notional_lab = sprintf('%.1f%%', 100 * notional_prop),
    ms_lab = sprintf('%.1f%%', 100 * ms_prop)
  ) |>
  arrange(n_rounds, win_series, win_round) |> 
  filter(win_round) |> 
  transmute(
    n_rounds,
    across(win_series, ~ifelse(.x, 'yes', 'no')),
    n,
    total,
    prop_lab,
    notional_lab,
    ms_lab
  ) |> 
  gt::gt() |> 
  gt::cols_label(
    n_rounds = 'r',
    win_series = 'Win series?',
    n = 'r+',
    total = 'N',
    prop_lab = 'O',
    notional_lab = 'a',
    ms_lab = 'b'
  ) |> 
  gt::as_latex() |> 
  cat()
```

Given that people typically perceive streaks as beginning after the third success (or failure) at minimum [@carlson2007], We focus on streaks of three round wins.[^21] Table \ref{tbl:cod-pw3r-pl3r} compares the observed round win rate $P^{w,kr}$ following streaks of $k=3$ round wins given the series outcome ($r$ rounds and winner) with the notional and MS expected proportions, $\hat{P}^{+|k,r}_0$ and $\hat{P}^{+|k,r}_{MS}$ respectively.

[^21]: Three happens to also be a reasonable number for series that last at maximum 11 rounds.

```{=tex}
\begin{longtable}{rcrrrrr}
\caption{Given the round win streak $k=3$, the length of the series ($r$ rounds), and the series winner, the observed count of rounds wins, $r^{+|k=3,r}$, and proportion of round wins, $P^{+|k=3,r}$, among $N^{k=3,r}$ instances where a team could win after the streak ($P^{+|k=3,r} = \frac{r^{+|k=3,r}}{N^{k=3,r}}$). Additionally, the notional and MS expected proportions, $\hat{P}^{+|k=3,r}_0$ and $\hat{P}^{+|k=3,r}_{MS}$ respectively.}
\label{tbl:cod-pw3r-pl3r} \\

\toprule
$r$ & \text{Win series?} & $r^{+|k=3,r}$ & $N^{k=3,r}$ & $P^{+|k=3,r}$ & $\hat{P}^{+|k=3,r}_0$ & $\hat{P}^{+|=3k,r}_{MS}$ \\ 
\midrule

7 & yes & 156 & 209 & 74.6\% & 75.0\% & 75.7\% \\ 
8 & yes & 130 & 209 & 62.2\% & 60.0\% & 61.9\% \\ 
9 & yes & 100 & 193 & 51.8\% & 50.0\% & 52.7\% \\ 
10 & no & 8 & 60 & 13.3\% & 14.3\% & 26.7\% \\ 
10 & yes & 66 & 151 & 43.7\% & 42.9\% & 44.7\% \\ 
11 & no & 31 & 129 & 24.0\% & 25.0\% & 30.8\% \\ 
11 & yes & 60 & 150 & 40.0\% & 37.5\% & 38.8\% \\ 

\bottomrule
\end{longtable}
```
With the exception of $\hat{P}^{+|k,r}_{MS}$ when $r = 10$ and the eventual series loser is the team that wins after a streak of three round wins[^22], all un-adjusted binomial test $p$-values are greater than the typical $\alpha = 0.05$ threshold, implying that we cannot reject the null hypothesis that the expected notional and MS post-streak round win rates are different than the observed proportion. Adjusting the $p$-values with the Benjamini & Yekutieli (BY) correction [-@benjamini2001], the null hypothesis cannot be rejected for any case.[^23]

[^22]: This implies that the opponent, the eventual series winner, goes on to win the series 6-4 after going down 0-4. This is the only scenario in which one team wins four rounds consecutively but loses a best-of-11 series in 10 rounds.

[^23]: As noted before, the MS expectations may be unreliable for CoD SnD, so one is inclined to prefer the results of the notional binomial tests.

When performing the same tests for streaks of two, four, and five, there is no case in which We can reject the binomial null hypothesis for the expected notional probability $p^{+|k,r}_0$. The null hypothesis can only be rejected for the expected MS probability $p^{+|k,r}_{MS}$ when $k = 5, r = 7$ after applying the BY p-value correction.[^24]

[^24]: At 36, the sample size for \$k = 5, r = 7\$ is not as large as most other combinations of \$k\$ and \$r\$.

```{r}
#| label: cod_round_win_prop_after_k_wins_i_rounds
summarize_cod_win_prop_after_k_wins_i_rounds <- function(k) {
  probs_nx_k <- crossing(
    n_rounds = 7L:11L,
    round = 3L:11L,
    win_series = c(TRUE, FALSE),
    win_round = c(TRUE, FALSE)
  ) |> 
    filter(round >= (!!k + 1L), n_rounds > round) |> 
    compute_probs_nx_k(k)
  
  postprocess_round_streaks(
    k = k,
    probs_nx_k = probs_nx_k,
    round
  )
}

init_cod_round_win_prop_after_k_wins_i_rounds <- tibble(win_streak = 3L) |>
  mutate(
    data = map(win_streak, summarize_cod_win_prop_after_k_wins_i_rounds)
  ) |>
  unnest(data) |> 
  select(-starts_with('ms'))

cod_round_win_prop_after_k_wins_i_rounds <- init_cod_round_win_prop_after_k_wins_i_rounds |>
  group_by(win_streak, win_round, n_rounds, round) |> 
  mutate(
    total = sum(n),
    prop = n / total
  ) |> 
  ungroup() |> 
  mutate(
    notional_p_value = vectorized_binom_test(n, total, p = notional_prop)$p.value |> round(2)
  )

# ## example of why we needed to recalculate prop... prop and notional_prop should sum to 1, grouped by win_streak and win_round
# cod_round_win_prop_after_k_wins_i_rounds |> 
#   filter(win_streak == 3, n_rounds == 11, round == 10)
# 
# ## 5-3?
# cod_round_win_prop_after_k_wins_i_rounds |> 
#   filter(win_streak == 2) |> 
#   filter(n_rounds == 11, round == 11)
```

```{r}
#| label: cod_round_win_prop_after_k_wins_i_rounds-table

cod_round_win_prop_after_k_wins_i_rounds |> 
  mutate(
    across(notional_p_value, p.adjust)
  ) |>
  filter(
    win_round,
    # round >= (n_rounds - 3)
    n_rounds >= 10,
    win_streak == 3
  ) |>  
  filter(total >= 10) |> 
  mutate(
    across(
      matches('p_value'), 
      ~case_when(
        .x <= 0.01 ~ '<=0.01', 
        TRUE ~ sprintf('%.2f', .x)
      )
    ),
    prop_lab = scales::percent(prop, accuracy = 0.1),
    notional_lab = scales::percent(notional_prop, accuracy = 0.1)
  ) |>
  arrange(n_rounds, round, win_series, win_round) |> 
  transmute(
    n_rounds,
    round,
    across(win_series, ~ifelse(.x, 'yes', 'no')),
    n,
    total,
    prop_lab,
    notional_lab
  ) |> 
  gt::gt() |> 
  gt::cols_label(
    n_rounds = 'r',
    round = 'i',
    win_series = 'Win series?',
    n = 'r+',
    total = 'N',
    prop_lab = 'O',
    notional_lab = 'a'
  ) |> 
  gt::as_latex() |> 
  cat()

```

Now let us explicitly consider the round, $i$. As shown in Table \ref{tbl:cod-pw3ri-pl3ri}, the notional win rate in the round $i$ immediately following a streak of $k$ round wins in a series lasting $r$ rounds, $\hat{P}{+|k,r,i}_0$, is statistically different than the observed $P^{+|k,r,i}$ in several cases, notably when $r = i$ for each of $r \in [9, 10, 11]$.[^25] Interestingly, the observed rate is greater than the expected rate in each case where we can reject the null hypothesis, whereas the observed rate is less than the expected rate in all other cases, as well in a strong majority of cases not shown.

[^25]: The null can also be rejected for $r \in [7, 8]$, although these are not shown, and the sample sizes are smaller.

```{=tex}
\begin{longtable}{rrcrrrr}
\caption{Given the round $i$, the round win streak $k=3$, the length of the series ($r$ rounds), and the series winner, the observed count of rounds wins, $r^{+|k=3,r,i}$, and proportion of round wins, $P^{+|k=3,r,i}$, among $N^{k=3,r,i}$ instances where a team could win after the streak ($P^{+|k=3,r,i} = \frac{r^{+|k=3,r,i}}{N^{k=3,r,i}}$). Additionally, the notional proportion, $\hat{P}^{+|k=3,r,i}_0$, and the $p$-value of a binomial test comparing $\hat{P}^{+|k=3,r,i}_0$ to the observed proportion $P^{+|k=3,r,i}$. Table restricted to $r \in [10, 11]$ and $i < r$ and $N^{k=3,r,i} \geq 10$ for brevity.}
\label{tbl:cod-pw3ri-pl3ri} \\
\toprule
$r$ & $i$ & \text{Win series?} & $r^{+|k=3,r,i}$ & $N^{k=3,r,i}$ & $P^{+|k=3,r,i}$ & $\hat{P}^{+|k=3,r,i}_0$\\ 
\midrule

10 & 7 & no & 2 & 13 & 15.4\% & 14.3\% \\ 
10 & 7 & yes & 11 & 13 & 84.6\% & 42.9\% \\ 
10 & 8 & no & 1 & 10 & 10.0\% & 14.3\% \\ 
10 & 8 & yes & 9 & 10 & 90.0\% & 42.9\% \\ 
11 & 5 & no & 9 & 13 & 69.2\% & 25.0\% \\ 
11 & 5 & yes & 4 & 13 & 30.8\% & 37.5\% \\ 
11 & 6 & no & 4 & 13 & 30.8\% & 25.0\% \\ 
11 & 6 & yes & 9 & 13 & 69.2\% & 37.5\% \\ 
11 & 7 & no & 3 & 10 & 30.0\% & 25.0\% \\ 
11 & 7 & yes & 7 & 10 & 70.0\% & 37.5\% \\ 
11 & 9 & no & 5 & 15 & 33.3\% & 25.0\% \\ 
11 & 9 & yes & 10 & 15 & 66.7\% & 37.5\% \\ 
11 & 10 & no & 5 & 10 & 50.0\% & 25.0\% \\ 
11 & 10 & yes & 5 & 10 & 50.0\% & 37.5\% \\ 

\bottomrule
\end{longtable}
```
```{r}
#| label: cod_round_arrangements
library(randtests)
simulate_cod_round_arrangements <- function(p = 0.5, n_sims = 10000, seed = 42) {
  n_rounds_max <- 11
  set.seed(seed)
  w <- sample(c(0, 1), size = n_rounds_max * n_sims, replace = TRUE, prob = c(1 - p, p))
  m <- matrix(w, nrow = n_sims, ncol = n_rounds_max)
  # data.frame(x)
  df <- as_tibble(m)
  names(df) <- sprintf('%d', 1:n_rounds_max)
  df$i <- 1:nrow(df)
  
  sim_rounds <- tibble(
    i = rep(1:n_sims, each = n_rounds_max),
    r = rep(1:n_sims, times = n_rounds_max),
    w = w
  ) |> 
    group_by(i) |> 
    mutate(
      cumu_w = cumsum(w),
      cumu_l = cumsum(w == 0)
    ) |> 
    ungroup() |> 
    mutate(
      cumu_wl_max = ifelse(cumu_w > cumu_l, cumu_w, cumu_l)
    ) |> 
    filter(cumu_wl_max <= 6)
  
  sim_rounds <- df |> 
    pivot_longer(
      -i,
      names_to = 'r',
      values_to = 'w'
    ) |> 
    mutate(
      across(r, as.integer)
    ) |> 
    group_by(i) |> 
    mutate(
      cumu_w = cumsum(w),
      cumu_l = cumsum(w == 0)
    ) |> 
    ungroup() |> 
    mutate(
      cumu_wl_max = ifelse(cumu_w > cumu_l, cumu_w, cumu_l)
    ) |> 
    filter(cumu_wl_max <= 6)
  
  sim_rounds_to_drop <- anti_join(
    sim_rounds |> 
      filter(cumu_wl_max == 6L),
    sim_rounds |> 
      filter(cumu_wl_max == 6L) |> 
      group_by(i) |> 
      slice_min(r, n = 1) |> 
      ungroup(), 
    by = c('i', 'r', 'w', 'cumu_w', 'cumu_l', 'cumu_wl_max')
  )
  
  sim_rounds <- sim_rounds |> 
    anti_join(
      sim_rounds_to_drop, 
      by = c('i', 'r', 'w', 'cumu_w', 'cumu_l', 'cumu_wl_max')
    )
  
  ## always from offensive perspective
  pre_expected_records <- sim_rounds |> 
    inner_join(
      sim_rounds |> 
        filter(cumu_wl_max == 6) |> 
        mutate(
          zeros_win = cumu_l == cumu_wl_max
        ) |> 
        select(i, zeros_win),
      by = 'i'
    ) |> 
    mutate(
      across(w, ~ifelse(zeros_win, abs(1 - .x), .x))
    )
  
  pre_expected_records |> 
    group_by(i) |> 
    summarize(
      cumu_w = max(cumu_w),
      cumu_l = max(cumu_l),
      ws = paste0(w, collapse = '-')
    ) |> 
    ungroup() |> 
    mutate(
      wins = ifelse(cumu_w == 6, cumu_w, cumu_l),
      losses = ifelse(cumu_w == 6, cumu_l, cumu_w),
      n_rounds = wins + losses
    ) |> 
    count(n_rounds, ws, sort = TRUE) |> 
    mutate(prop = n / sum(n))
}

cod_expected_round_arrangements_mle <- simulate_cod_round_arrangements(0.575)

cod_actual_round_arrangements <- cod_rounds |> 
  filter(win_series) |> 
  mutate(across(win_round, as.integer)) |> 
  group_by(year, event, series) |> 
  summarize(
    wins = max(cumu_w),
    losses = max(cumu_l),
    ws = paste0(win_round, collapse = '-')
  ) |> 
  ungroup() |> 
  mutate(
    n_rounds = wins + losses
  ) |> 
  count(n_rounds,  ws, sort = TRUE) |> 
  mutate(prop = n / sum(n))

perform_run_tests <- function(cod_expected_round_arrangements) {
  suppressWarnings(
    cod_run_tests <- cod_expected_round_arrangements |> 
      select(n_rounds, ws) |> 
      separate(ws, into = as.character(1:11), remove = FALSE) |> 
      pivot_longer(
        -c(n_rounds, ws),
        names_to = 'round',
        values_to = 'w',
        values_drop_na = TRUE
      ) |> 
      mutate(
        across(c(round, w), as.integer)
      ) |> 
      # filter(record != '6-0') |> 
      select(-round) |> 
      group_by(n_rounds, ws) |> 
      summarize(
        w = list(w)
      ) |> 
      ungroup() |> 
      mutate(
        p_value = map_dbl(w, ~randtests::runs.test(.x, threshold = 0.5)$p.value),
        is_significant = p_value <= 0.05
      ) |> 
      select(n_rounds, ws, p_value, is_significant)
  )
  
  expected_total <- sum(cod_expected_round_arrangements$n)
  actual_total <- sum(cod_actual_round_arrangements$n)
  cod_round_arrangements <- cod_expected_round_arrangements |> 
    rename(n_expected = n, prop_expected = prop) |>
    mutate(
      n_expected_adj = n_expected * (!!actual_total) / (!!expected_total)
    ) |> 
    left_join(
      cod_actual_round_arrangements |> 
        rename(n_actual = n, prop_actual = prop),
      by = c('n_rounds', 'ws')
    ) |> 
    inner_join(
      cod_run_tests,
      by = c('n_rounds', 'ws')
    ) |> 
    mutate(
      across(n_actual, replace_na, 0L),
      across(prop_actual, replace_na, 0)
    )
}

cod_round_arrangements_mle |> 
  # mutate(
  #   total_actual = sum(n_actual),
  #   total_expected = sum(n_expected)
  # ) |> 
  filter(!is.na(p_value)) |> 
  filter(is_significant) |> 
  mutate(
    total_actual = sum(n_actual),
    total_expected_adj = sum(n_expected_adj)
  ) |> 
  mutate(
    prop_p_value = vectorized_prop_test(n_actual, total_actual, round(n_expected_adj), round(total_expected_adj))$p.value,
    orig_prop_p_value = prop_p_value,
    across(prop_p_value, ~p.adjust(.x, method = 'BY') |> round(3))
  )

cod_round_arrangements_mle <- cod_expected_round_arrangements_mle |> perform_run_tests()
cod_round_arrangements_mle |> 
  filter(is_significant) |> 
  filter(n_rounds < 11) |> 
  transmute(
    n_rounds,
    ws,
    n_actual,
    across(prop_actual, ~sprintf('%.2f%%', 100 * .x)),
    across(n_expected_adj, round, 2),
    across(prop_expected, ~sprintf('%.2f%%', 100 * .x))
  ) |> 
  gt::gt() |> 
  gt::cols_label(
    n_rounds = 'r',
    ws = 'Sequence',
    n_actual = 'a',
    prop_actual = 'b',
    n_expected_adj = 'c',
    prop_expected = 'd'
  ) |> 
  gt::as_latex() |> 
  cat()
```

### Wald-Wolfowitz runs test

In Table \ref{tbl:cod-runs}, the observed and expected count of sequences, $N^{\zeta r}$ and $\hat{N}^{\zeta r}$ respectively, are shown for sequences, $\zeta(r)$, for which one can reject the Wald-Wolfowitz null hypothesis at a confidence level of $\alpha = 0.05$, for $r \in [8, 9, 10]$. (In addition to these 13, there are 12 additional sequences for $r = 11$.) The relative frequency of the expected proportions are based on 10,000 simulations using the constant round probability $\phi_2 = 0.575$. A test for difference between the actual and expected proportions of all sequences indicates that the null hypothesis---that the two proportions are equal---cannot be rejected for any of the 25 significant sequences.

```{=tex}
\begin{longtable}{rlrrrr}

\caption{Given the length of the series ($r$ rounds), the sequence of round wins by the series winner $^\zeta(r)$, where round wins $r^w$ and losses $r^-$ are indicated by 1 and 0 respectively, among sequences that reject the Wald-Wolfowitz null hypothesis for $r \in [8, 9, 10]$. The observed count, $N^{\zeta r}$, and proportion, $P^{\zeta r}$, of all possible sequences, as well as the expected count, $\hat{N}^{\zeta r}$, and proportion, $\hat{P}^{\zeta r}$. $\hat{N}^{\zeta r}$ is scaled to the observed number of series played, hence its non-integer value.}
\label{tbl:cod-runs} \\

\toprule
r & $\zeta(r)$ & $N^{\zeta r}$ & $P^{\zeta r}$ & $\hat{N}^{\zeta r}$ & $\hat{P}^{\zeta r}$ \\ 
\midrule
8 & 0-0-1-1-1-1-1-1 & 4 & 0.47\% & 7.67 & 0.90\% \\ 
9 & 0-0-0-1-1-1-1-1-1 & 4 & 0.47\% & 3.75 & 0.44\% \\ 
10 & 1-1-1-1-0-0-0-0-1-1 & 1 & 0.12\% & 2.39 & 0.28\% \\ 
10 & 1-0-0-0-0-1-1-1-1-1 & 0 & 0.00\% & 2.04 & 0.24\% \\ 
10 & 1-0-1-0-1-1-0-1-0-1 & 3 & 0.35\% & 2.04 & 0.24\% \\ 
10 & 1-1-1-0-0-0-0-1-1-1 & 2 & 0.23\% & 2.04 & 0.24\% \\ 
10 & 0-0-0-0-1-1-1-1-1-1 & 2 & 0.23\% & 1.79 & 0.21\% \\ 
10 & 1-0-1-0-1-0-1-1-0-1 & 3 & 0.35\% & 1.70 & 0.20\% \\ 
10 & 1-0-1-1-0-1-0-1-0-1 & 0 & 0.00\% & 1.70 & 0.20\% \\ 
10 & 1-1-0-0-0-0-1-1-1-1 & 1 & 0.12\% & 1.19 & 0.14\% \\ 
10 & 1-0-1-0-1-0-1-0-1-1 & 3 & 0.35\% & 1.11 & 0.13\% \\ 
10 & 1-1-0-1-0-1-0-1-0-1 & 0 & 0.00\% & 1.11 & 0.13\% \\ 
10 & 1-1-1-1-1-0-0-0-0-1 & 2 & 0.23\% & 1.02 & 0.12\% \\ 
\bottomrule
\end{longtable}
```
# Discussion

For the sake of brevity, we did not delve into win rates and streaks split by offensive or defensive role. For example, it would be interesting to look at whether the round win rate is higher after a streaks of three round wins when the team starts the streak winning as the offensive team. This would mean that, in the round immediately following the streak, the streaking team would be playing defense, where teams are slightly more likely to win on average. On the other hand, streaks of three starting with an offensive round win---theoretically, given $\tau_O$ = 47.7% the expected frequency is $\tau_O^2 \times (1 - \tau_O) \approx$ 11.9%---are likely to occur less frequently than such streaks starting with a defensive win---$\tau_O \times (1 - \tau_O)^2 \approx$ 13.0%---so We would want to account for sample size differences.

Further regarding future work, We've reached out to the Twitter user "R11stats", who privately tracks in-round player engagements.[^26] R11stats expressed intent on making the data public, which would allow for research into player-specific momentum.

[^26]: <https://twitter.com/R11stats>

Other talking points

-   We probably should have expected no hot hand effect given the small "skill gap" in the CoD relative to other esports (andecdotal, but most professional esports player, including CoD players themselves, would say this).

# References {.unnumbered}

::: {#refs}
:::
