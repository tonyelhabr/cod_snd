---
title: "They're Clutching up! Team Momentum in Round-Based Esports"
authors:
  - name: Tony ElHabr
    affiliations:
      - name: Georgia Institute of Technology
    email: anthonyelhabr@gmail.com
    url: https://tonyelhabr.rbind.io
abstract: |
  My research investigates patterns in round win percentages in professional Search and Destroy (SnD) matches of the popular first-person shooter game Call of Duty (CoD). First, I find evidence supprting the hypothesis that round win probability can be modeled as a constant across the series, although not at the naive 50%. Second, I examine post-streak round win probability, in search of evidence positive recency (the "hot hand" fallacy) or negative recency (the "gambler's falacy"). I find that teams perform significantly worse than expected after streaks of 2, 3, and 4 wins when series end up going to 9, 10, or 11 (maximum) rounds, suggesting the presence of negative recency.
bibliography: references.bib  
output:
  rticles::arxiv_article:
    includes:
      in_header: preamble.tex
---

```{r}
#| label: setup
#| include: false
#| echo: false
#| eval: true
knitr::opts_chunk$set(
  eval = FALSE,
  echo = FALSE,
  include = FALSE,
  message = FALSE,
  warning = FALSE
)
```

```{r}
#| label: setup-code
library(dplyr)
library(qs)
library(tidyr)
library(purrr)
library(gt)
library(scales)

cod_rounds <- qs::qread('data/cod_rounds.qs')
```

```{r}
#| label: descriptive-cod-snd-stats
cod_n_series <- cod_rounds |> 
  distinct(series_id) |> 
  nrow()

cod_n_rounds <- cod_rounds |> 
  distinct(series_id, round) |> 
  nrow()

cod_o_win_prop <- cod_rounds |> 
  filter(is_offense) |> 
  count(win_round) |> 
  mutate(prop = n / sum(n)) |> 
  filter(win_round) |> 
  pull(prop)

cod_o_win_prop_by_game <- cod_rounds |> 
  filter(is_offense) |> 
  count(game, win_round) |> 
  group_by(game) |> 
  mutate(prop = n / sum(n)) |> 
  ungroup() |> 
  filter(win_round) |> 
  select(game, n, prop)

pull_cod_o_win_prop_by_game <- function(.game) {
  cod_o_win_prop_by_game |> 
    filter(game == .game) |> 
    pull(prop) |> 
    scales::percent(accuracy = 0.1)
}
```

# Introduction

## Description of Call of Duty Search and Destroy

Call of Duty (CoD), first released in 2003, is one of the most popular first-person shooter (FPS) video game franchises of all-time. The most popular mode in the competitive scene is "Search and Destroy" (SnD).[^1] SnD is a one-sided game mode in which one team, the offensive side, tries to destroy one of two designated bomb sites on the map.

[^1]: SnD bears resemblance to "Bomb Defusal" in Counter-Strike and "Plant/Defuse" in Valorant, two other FPS games played in more popular professional leagues.

In professional CoD SnD, a team take turns playing offense and defense every round. They must win six rounds to win the series.[^2] A round can end in one of five ways:

[^2]: A maximum of 11 even rounds can be played. There is no "sudden death" or "win by two" rule like there are for SnD equivalent in professional Counter-Strike and Valorant matches.

1.  One team eliminates all members of the other team prior to a bomb plant. (Eliminating team wins.)
2.  The offensive team eliminates all members of the defensive team after a bomb plant.[^3] (Offense wins.)
3.  The defensive team defuses the bomb after a bomb plant.[^4] (Defense wins.)
4.  The offensive team does not make a plant by the time the round timer ends. (Defense wins.)

[^3]:
    -   The bomb can be picked up by any member of the offensive team.
    -   The bomb carrier is not obstructed at all by carrying the bomb (i.e. movement is the same, weapon usage is the same).
    -   The defense does not get any visual indication for who is carrying the bomb.
    -   A bomb plant takes five seconds. The timer resets if the player stops planting site prior to completing it.
    -   A bomb defuse takes seven seconds. The timer resets if the player "drops" the bomb.
    -   The bomb takes 45 seconds to defuse after being planted.

[^4]: Often the defensive team will try to eliminate all team members prior to making the defuse, but in some cases, they may try to "ninja" defuse.

I adopt the terminology "series" to refer to what CoD SnD players typically call a "match", so as to emulate the terminology of playoff series in professional leagues like the National Basketball Association, National Hockey League, and Major League Baseball. A "game" or a "match" in such leagues is analogous to a "round" of CoD SnD.

## Data

CoD has roughly gone through three eras of professional gaming: (1) Major League Gaming (MLG) tournaments prior to 2016; (2) the CoD World League (CWL), initiated in 2016; and (3) the 12-franchise CoD League (CDL), operating since 2020. The CDL has completed three year-long "seasons" as of August 2022.[^5]

[^5]: CoD is fairly unique compared to other esports in that it runs on an annual lifecycle (released coming in the late fall), where a new game is published every year under the same title. Each new game bears resemblance to past ones, often introducing relatively small variations ("improvements") to graphics, game modes, and other facets of gameplay. During the CDL era, the games released have been Modern Warfare (2020), Cold War (2021) and Vanguard (2022).

The data set consists of all SnD matches played in tournanaments and qualifiers during the CDL era, totaling 7,792 rounds across 852 series. Data was collected in spreadsheets by community member "IOUTurtle".[^6]

[^6]: Data: <https://linktr.ee/CDLArchive>. Author: <https://twitter.com/IOUTurtle>

The empirical offensive round win percentage across all rounds is 47.8%.[^7] Table \ref{tbl:cod-o-win-prop-by-series-state} shows round win percentages by series "state" (i.e. the number of round wins by each team prior to an upcoming round). Offensive round win rate is not quite constant, although never veers more than 10% from this global average.

[^7]: Offensive round win percentage has been nearly constant across the three games during the CDL era: 1. 47.2% in MW (2020) 2. 47.9% in Cold War (2021) 3. 48.1% in Vanguard (2022)

```{r}
#| label: cod_o_win_prop
cod_round_and_series_win_prop_by_side <- cod_rounds |>
  group_by(pre_cumu_w, pre_cumu_l, is_offense) |>
  summarize(
    n = n(),
    across(c(win_round, win_series), sum)
  ) |>
  ungroup() |>
  mutate(
    win_round_prop = win_round / n,
    win_series_prop = win_series / n
  )

cod_round_and_series_win_prop_by_side |>
  filter(is_offense) |>
  transmute(
    pre_cumu_w,
    pre_cumu_l,
    lab = sprintf('%.1f%%\n(%s)', round(100 * win_round_prop, 1), n)
  ) |>
  pivot_wider(
    names_from = pre_cumu_l,
    values_from = lab
  ) |>
  arrange(pre_cumu_w) |>
  gt::gt() |>
  gt::cols_label(
    pre_cumu_w = "Defense round wins",
  ) |>
  gt::tab_spanner(
    label = "Offense round wins",
    columns = `0`:`5`
  ) |>
  gt::as_latex()
```

```{=tex}
\begin{longtable}{crrrrrr}
\caption{Offensive round win rates for the upcoming round, given both the offensive and defensive team's prior number of round wins}\label{tbl:cod-o-win-prop-by-series-state} \\
\toprule
& \multicolumn{6}{c}{Offense round wins} \\ 
\cmidrule(lr){2-7}
Defense round wins & 0 & 1 & 2 & 3 & 4 & 5 \\ 
\midrule
0 & 47.8\%
(852) & 46.6\%
(408) & 43.1\%
(216) & 43.5\%
(115) & 43.3\%
(67) & 40.5\%
(37) \\ 
1 & 48.6\%
(444) & 49.3\%
(418) & 51.5\%
(309) & 43.4\%
(205) & 43.3\%
(120) & 39.4\%
(99) \\ 
2 & 52.8\%
(218) & 48.9\%
(305) & 48.9\%
(315) & 46.6\%
(262) & 48.7\%
(189) & 42.1\%
(133) \\ 
3 & 54.5\%
(123) & 46.0\%
(200) & 49.6\%
(250) & 45.6\%
(248) & 44.4\%
(214) & 44.8\%
(174) \\ 
4 & 56.9\%
(65) & 54.5\%
(145) & 47.2\%
(193) & 44.7\%
(228) & 55.2\%
(221) & 50.5\%
(208) \\ 
5 & 47.4\%
(38) & 49.4\%
(83) & 47.1\%
(136) & 50.9\%
(175) & 45.2\%
(177) & 46.0\%
(202) \\ 
\bottomrule
\end{longtable}
```
# Literature review

There have been a handful of studies of the distribution of games played in a series of a professional sport. Most assume a constant probability $\phi$ of a given team winning a game in the series, regardless of the series state. Mosteller [-@mosteller1952] observed that the American League had dominated the National League in Major League Baseball's (MLB) World Series matchups, implying that matchups should not modeled with $\phi = 0.5$. Mosteller proposed three approaches for identifying the optimal constant probability value of the stronger team in the World Series, finding $\phi \approx 0.65$. in each case: (1) solving for $p$ from the empirical average number of games won by the loser of the series, which he called the "method of moments" approach; (2) maximizing the likelihood that the sample would have been drawn from a population in which the probability of a team winning a game is constant across the series (i.e. maximum likelihood), and (3) minimizing the chi-square goodness of fit statistic for $\phi$.

Chance [-@chance2020] re-examines the constant probability notion in Major League Baseball's (MLB) World Series (1923--2018), the National Basketball Association's (NBA) Finals (1951--2018), and the National Hockey League's (NHL) Stanley Cup (1939--2018). Chance finds strong evidence against the null hypothesis of $\phi = 0.5$ in the MLB and NHL championship series when applying Mosteller's first and second methods. Chance goes on to outline a conditional probability framework (likelihood of winning a game given the series state) which can exactly explain the distribution of the number of games played.

Momentum, one of most discussed topics in sports analytics, goes hand-in-hand with a discussion of the nature of series outcomes.[^8] Two opposing fallacies are observed in the context of momentum: the "gambler's fallacy" (negative recency) and "hot hand fallacy" (positive recency). Per Ayton et al. [-@ayton2004], negative recency is "the belief that, for random events, runs of a particular outcome ... will be balanced by a tendency for the opposite outcome", while positive recency is the expectation of observing future results that match recent results.

[^8]: We often use use "streaks" and momentum interchangeably, but as [@steeger2021] note, momentum implies dependence between events, whereas streaking does not.

Studying both player streaks and team streaks in basketball, in both observational and controlled settings. Gilovich et al. [-@gilovich1985], henceforth GVT, do not find evidence for the hot hand phenomenon. However, Miller and Sanjurjo [-@miller2018], henceforth MS, refuted the conclusions of GVT, proving a framework for quantifying streak selection bias, which effectively works in the manner posited by the gambler's fallacy[^9]. Specifically, MS say that a "bias exists in a common measure of the conditional dependence of present outcomes on streaks of past outcomes in sequential data" implying that, under i.i.d. conditions, "the proportion of successes among the outcomes that immediately follow a streak of consecutive successes is expected to be strictly less than the underlying (conditional) probability of success". When applying streak selection bias to GVT.'s data, MS come to the opposite conclusions as GVT.

[^9]: Streak selection bias, "in conjunction with a quasi-Bayesian model of decision making under sample size neglect... provides a novel structural candidate explanation for the persistence of gambler's fallacy beliefs", per MS.

Despite the plethora of existing research on games played in a series and momentum in sports, these topics have yet to be investigated heavily in esports. Work has been done to examine in-round win probability in other FPS titles such as Counter-Strike [@xenopoulos2022] and Valorant [@derover2021], both of which are round-based like CoD SnD. However, research on round-level trends is sparse, perhaps because games like Counter-Strike and Valorant both have economic aspects that can create clear advantages on side in a given round, given how prior rounds played out.

Additionally, both Counter-Strike and Valorant have overtime rules and blocked offensive/defensive roles (i.e. playing either offense or defense for many consecutive rounds). On the other hand, teams in CoD SnD rotate sides every round, analogous to a 1-1-1-1-1-1-1 format for home advantage in best-of-seven series for professional sports like the MLB, NBA, and NHL.[^10] While theoretically one might be able to account for any kind of balanced rotation, such as a "blocky" on like a 5-5-1, the rotation of team sides every round is convenient, particularly for convincing ourselves that rounds could reasonably be modeled as i.i.d. Bernoulli trials.

[^10]: 1-1-1-1-1-1-1 is not used today in these leagues, but it was at least one in each league.

# Methodology

## Distribution of rounds played {#sec:method-rounds-played}

The formula for the expected proportion of seriesn a best-of-$s$ format ($s = 11$ rounds for CoD SnD), ending in $r$ rounds ($r \leq s$), $\hat{\Phi}(r)$, for a constant round win probability $\phi$ ($0 \leq \phi \leq 1$) for one team[^11] is

[^11]: If $\phi > 0.5$, then one might say that this team is the better team (known in hindsight).

$$
m = \frac{s + 1}{2}
$$

```{=tex}
\begin{equation}\protect\hypertarget{eq:m}{}{
m = \frac{s + 1}{2}
}\label{eq:m}\end{equation}
```
```{=tex}
\begin{equation}\protect\hypertarget{eq:series-length}{}{
\hat{\Phi}(r) = \frac{(r - 1)!}{(m - 1)!(r - s)!}(\phi^{m}(1 - \phi)^{r - m} + \phi^{r - m}(1 - \phi)^m).
}\label{eq:series-length}\end{equation}
```
To evaluate the constant round win probability hypothesis--that is, that the expected and observed round win rates, $\hat{\Phi}(r)$ and $\Phi(r)$ respectively, are equal to one another--we can compute the chi-square goodness of fit statistic, $\chi^2$.

```{=tex}
\begin{equation}\protect\hypertarget{eq:chi-squ}{}{
\chi^2 = \sum^R \frac{(\Phi(r) - \hat{\Phi}(r))^2}{\hat{\Phi}(r)}
}\label{eq:chi-squ}\end{equation}
```
For CoD SnD, $r \in R = [6, 7, 8, 9, 10, 11]$.

## Momentum {#sec:method-momentum}

Removing our knowledge of a streak, we might model the Bernoulli round win probability as

```{=tex}
\begin{equation}\protect\hypertarget{eq:pwr}{}{
p^{w|r} = p(\text{win | r})=\{
\begin{array}{cl}
\frac{m}{r}, & \text{team wins series} \\
\frac{r - m}{r}, & \text{team loses series}
\end{array}.
}
\label{eq:pwr}
\end{equation}
```
The Bernoulli round loss probability after a streak of $k$ round wins, $p^{\ell|kr}_0$, can be formulated symmetrically.

As shown by MS, we should expect the proportion of rounds wins immediately following a streak of $k$ rounds wins for a series lasting $r$ rounds, $\hat{P}^{w|kr}_{MS}$, to be strictly less than $p^{w|r}$.[^12]

[^12]: See Appendix E.1 of MS for details on the proof that follows.

> Theorem 1: *Let* $\mathbf{X} = \{X_i\}^{n}_{i=1}, n \geq 3$*, be a sequence of independent Bernoulli trials, each with probability of success* $0 < \pi < 1$*. Let* $\hat{\Pi}_k(\mathbf{X})$ *be the proportion of successes on the subset of trials* $I_k(\mathbf{X})$ *that immediately follow* $k$ consecutive successes, that is, $\hat{\Pi}_k(\mathbf{X}) := \sum_{i \in I_k(\mathbf{X})} X_i | I_k(\mathbf{X}) |. \hat{\Pi}_k$ *is a biased estimate of* $\mathbb{\Pi}(X_t = 1 | \prod_{j=t-k}^{t-1} X_j = 1) \equiv p$ *for all* $k$ *such that* $1 \leq k \leq n - 2$*. In particular,* $E[\hat{\Pi}_k(\mathbf{X}) | I_k(\mathbf{X}) \neq \emptyset] < \pi.$

MS note that there does not exists a closed form representation for $E[\hat{\Pi}_k(\mathbf{X}) | I_k(\mathbf{X}) \neq \emptyset]$ for $k > 1$. ($\hat{\Pi}_k(\mathbf{X})$ is the analogue for $\hat{P}^{w|kr}_{MS}$ in my notation for CoD SnD.) Figure 1 shows how the expected value varies as a function of the total number of trials $n$, given $\pi$ and $k > 1$.[^13]

[^13]: I've adapted the code from Vafa [-@vafa2017], which implements MS's framework [-@miller2018].

```{r}
#| label: npkd
## http://keyonvafa.com/hot-hand/
get_post_streak_prob <- function(n, k, p = 0.5) {
  tosses <- rbinom(n, 1, p)
  runs <- rle(tosses)
  n_neg_after <- length(which(runs$values == 1 & runs$lengths >= k))
  n_pos_after <- sum(runs$lengths[which(runs$values == 1 & runs$lengths >= k)] - k)
  
  ## edge case
  if (n %in% cumsum(runs$lengths)[which(runs$values == 1 & runs$lengths >= k)]) {
    n_neg_after <- n_neg_after - 1
  }
  
  n_pos_after / (n_pos_after + n_neg_after)
}

simulate_post_streak_prob <- function(sims = 10000, seed = 42, ...) {
  withr::local_seed(seed)
  rerun(
    sims,
    get_post_streak_prob(...)
  ) |> 
    flatten_dbl() |> 
    mean(na.rm = TRUE)
}

# library(extrafont)
# library(ggplot2)
# library(latex2exp)
# # set.seed(42)
# # runs <- rerun(
# #   1000,
# #   crossing(
# #     n = 1:50,
# #     k = 2:4,
# #     p = 0.5
# #   ) |>
# #     mutate(
# #       next_p = pmap_dbl(list(n, k, p), ~simulate_post_streak_prob(sims = 1000, n = ..1, k = ..2, p = ..3))
# #     )
# # ) |>
# #   reduce(bind_rows)
# # qs::qsave(runs, 'data/runs_1000x1000_nkp.qs')
# runs <- qs::qread('data/runs_1000x1000_nkp.qs')
# 
# agg_runs <- runs |>
#   filter(!is.nan(next_p)) |>
#   group_by(p, k, n) |>
#   summarize(
#     across(next_p, mean)
#   ) |>
#   ungroup() |>
#   arrange(p, k)
# 
# extrafont::loadfonts(quiet = TRUE)
# theme_set(theme_classic())
# theme_update(
#   text = element_text(family = 'CMU Typewriter Text')
# )
# 
# p <- agg_runs |>
#   arrange(p, k, n) |>
#   mutate(
#     across(k, factor)
#   ) |>
#   ggplot() +
#   aes(x = n, y = next_p, color = k, group = k) +
#   guides(
#     color = guide_legend(
#       title = 'streak length (k)',
#       title.hjust = 0.5,
#       nrow = 1, override.aes = list(size = 3)
#     )
#   ) +
#   geom_line() +
#   geom_hline(aes(yintercept = p)) +
#   labs(x = 'number of trials (n)', y = expression('post-streak probability of success'~(pi))) +
#   theme(
#     legend.position = c(0.5, 0.8)
#   )
# p
# 
# ggsave(
#   p,
#   filename = 'paper/images/pwkr_ms.png',
#   width = 5.5,
#   height = 3
# )
```

```{=tex}
\begin{figure}
\centering
\includegraphics{images/pwkr_ms.png}
\caption{The expected value of the proportion of successes on trials that immediately follow $k$ consecutive successes, $E[\hat{\Pi}_k(\mathbf{X}) | I_k(\mathbf{X}) \neq \emptyset]$, for Bernoulli trial success $\pi = 0.5$ and streak lengths $k \in [2, 3, 4]$, as a function of the total number of trials $n.$}
\end{figure}
```
My context is fundamentally different from that of GVT and MS, both of whom focus on longitudinal data in controlled settings. GVT also perform statistical tests on shots from players in live games, i.e. "observational" data, but they note that their findings are likely affected player shot selection in the face of defensive strategy by the opposing team. The number of trials is fixed in their experimental designs, but in CoD SnD, the number of rounds played is determined as a function of the max number of possible rounds ($s$) and whether or not the team wins the series, as shown in Equation \ref{eq:pwr}. The Bernoulli trial success probability, i.e. a round win in CoD SnD, is not independent of the opponent.

Consequently, a statistical test of the difference in $\hat{P}^{w|kr}$ and $\hat{P}^{\ell|kr}$, as performed by GVT and MS to evaluate their respective hypothesis regarding $E[\hat{P}_k(\mathbf{X}) | I_k(\mathbf{X}) \neq \emptyset]$ (Theorem 1), is not appropriate.

Let us consider another form of the expected proportion of rounds won immediately after a streak of $k$ round wins in a best-of-$s$ series given the length of the series ($r$ rounds), the "hindsight" proportion $\hat{P}^{w|kr}_0$. The Bernoulli round win probability underlying $\hat{P}^{w|kr}_0$ is

```{=tex}
\begin{equation}\protect\hypertarget{eq:pwkr}{}{
p_0^{w|kr} = p_0(\text{win | k, r})=\{
\begin{array}{cl}
\frac{m - k}{i - k}, & \text{team wins series} \\
\frac{s - m - k}{i - k}, & \text{team loses series}
\end{array}.
}
\label{eq:pwkr}
\end{equation}
```
A binomial test for the expected proportion of round wins following streaks of $k$ round wins in a series lasting $r$ rounds, $\hat{P}^{w|kr}_0$, assuming $p^{w|kr}_0$ as the probability of success, can be used to verify that $\hat{P}^{w|kr}_0$ is reasonable as to use as a baseline with which to compare $\hat{P}^{w|kr}_{MS}$. If the binomial test shows that we cannot reject the null hypothesis that the expected $\hat{P}^{w|kr}_0$ is different from the observed proportion $P^{w|kr}$.

A proportion test of $\hat{P}^{w|kr}_0$ and $\hat{P}^{w|kr}_{MS}$ can tell us whether the momentum exists in CoD SnD. A null result means we cannot say that there is a difference between the hindsight expected proportion $\hat{P}^{w|kr}_0$ and the expected proportion adjusted for streak-selection bias, $\hat{P}^{w|kr}_0$.

# Results

First, I investigate the constant probability assumption and the distribution of rounds played in a series. Chance's [-@chance2020] work is closely related to mine, and, in fact, provides a guide for this investigation. Afterwards, I investigate post-streak win rates and the context of momentum, leveraging MS's [-@miller2018] framework for streak selection bias.

## Distribution of rounds played {#sec:results-rounds-played}

Using Equation \ref{eq:chi-squ}, I find that $\chi^2 = 16.0$ (p-value of 0.0068) for the naive constant round win probability $\phi_0 = 0.5$. Thus, I can comfortably reject the constant probability null hypothesis for $\phi_0 = 0.5$, even at a confidence level of $\alpha = 0.01$.

```{r}
#| label: cod_series_outcome_prop
.max_round <- 11
.cutoff <- 6
prob_of_series_lasting_r_rounds <- function(r, p = 0.5, s) {
  m <- as.integer((s + 1) / 2)
  (factorial(r - 1) / (factorial(m - 1) * factorial(r - m))) * (p^m * (1 - p)^(r - m) + p^(r - m) * (1 - p)^m)
}

expected_series_streaks_of_outcomes <- function(m, n) {
  factorial(m + n) / (factorial(m) * factorial(n))
}

# https://raw.githubusercontent.com/dgrtwo/splittestr/master/R/vectorized-prop-test.R
vectorized_prop_test_approx <- function(a, b, c, d) {
  n1 <- a + b
  n2 <- c + d
  n <- n1 + n2
  p <- (a + c) / n
  E <- cbind(p * n1, (1 - p) * n1, p * n2, (1 - p) * n2)
  
  x <- cbind(a, b, c, d)
  
  DELTA <- a / n1 - c / n2
  YATES <- pmin(.5, abs(DELTA) / sum(1 / n1 + 1 / n2))
  
  STATISTIC <- rowSums((abs(x - E) - YATES)^2 / E)
  PVAL <- pchisq(STATISTIC, 1, lower.tail = FALSE)
  PVAL
}

vectorized_prop_test_exact <- function(a, b, c, d) {
  sapply(seq_along(a), function(i) {
    fisher.test(cbind(c(a[i], c[i]), c(b[i], d[i])))$p.value
  })
}

vectorized_prop_test <- function(x1, n1, x2, n2, conf.level = 0.95) {
  a <- x1
  b <- n1 - x1
  c <- x2
  d <- n2 - x2
  
  # if any values are < 20, use Fisher's exact test
  exact <- (a < 20 | b < 20 | c < 20 | d < 20)
  
  pvalue <- rep(NA, length(a))
  
  if (any(exact)) {
    pvalue[exact] <- vectorized_prop_test_exact(a[exact], b[exact], c[exact], d[exact])
  }
  if (any(!exact)) {
    pvalue[!exact] <- vectorized_prop_test_approx(a[!exact], b[!exact], c[!exact], d[!exact])
  }
  
  mu1 <- a / (a + b)
  mu2 <- c / (c + d)
  
  ## confidence interval
  alpha2 <- (1 - conf.level) / 2
  DELTA <- mu2 - mu1
  WIDTH <- qnorm(alpha2)
  alpha <- (a + .5) / (a + b + 1)
  beta <- (c + .5) / (c + d + 1)
  
  n <- n1 + n2
  YATES <- pmin(.5, abs(DELTA) / sum(1 / n1 + 1 / n2))
  
  z <- qnorm((1 + conf.level) / 2)
  WIDTH <- z * sqrt(mu1 * (1 - mu1) / n1 + mu2 * (1 - mu2) / n2)
  
  tibble(
    estimate = DELTA,
    conf.low = pmax(DELTA - WIDTH, -1),
    conf.high = pmin(DELTA + WIDTH, 1),
    p.value = pvalue
  )
}

cod_actual_round_streaks <- cod_rounds |> 
  filter(round <= .max_round) |> 
  filter(win_series) |> 
  mutate(across(win_round, as.integer)) |> 
  group_by(series_id) |> 
  summarize(
    wins = max(cumu_w),
    losses = max(cumu_l),
    ws = paste0(win_round, collapse = '-')
  ) |> 
  ungroup() |> 
  mutate(n_rounds = wins + losses) |> 
  unite(
    record, wins, losses, sep = '-'
  ) |>
  count(record, n_rounds, ws, sort = TRUE) |> 
  mutate(prop = n / sum(n))

summarize_cod_streaks <- function(p = 0.5) {
  
  expected_round_streaks <- tibble(
    n_rounds = .cutoff:.max_round
  ) |> 
    mutate(
      series_prop = map_dbl(n_rounds, ~prob_of_series_lasting_r_rounds(.x, s = .max_round, p = !!p)),
      n_expected_series_streaks = map_dbl(n_rounds, ~expected_series_streaks_of_outcomes(.cutoff, .x - .cutoff))
    ) |> 
    transmute(
      n_rounds,
      series_prop,
      prop = series_prop / n_expected_series_streaks
    )
  
  round_streaks <- full_join(
    cod_actual_round_streaks |> 
      rename_with(~sprintf('%s_actual', .x), c(n, prop)),
    expected_round_streaks |> 
      rename_with(~sprintf('%s_expected', .x), prop),
    by = 'n_rounds'
  )
  
  round_streak_prop <- round_streaks |> 
    drop_na() |> 
    mutate(
      prop_diff = prop_actual - prop_expected,
      total_actual = sum(n_actual),
      n_expected = round(prop_expected * total_actual),
      p = vectorized_prop_test(n_actual, total_actual, n_expected, total_actual)
    ) |> 
    select(-total_actual) |> 
    unnest_wider(p) |> 
    arrange(p.value)
  
  series_outcomes <- full_join(
    cod_actual_round_streaks |> 
      group_by(record, n_rounds) |> 
      summarize(
        across(n, sum)
      ) |> 
      ungroup() |> 
      mutate(prop = n / sum(n)) |> 
      rename_with(~sprintf('%s_actual', .x), c(n, prop)),
    expected_round_streaks |> 
      select(n_rounds, prop_expected = series_prop),
    by = 'n_rounds'
  )
  
  series_outcome_prop <- series_outcomes |> 
    drop_na() |> 
    mutate(
      prop_diff = prop_actual - prop_expected,
      total_actual = sum(n_actual),
      n_expected = round(prop_expected * total_actual),
      p = vectorized_prop_test(n_actual, total_actual, n_expected, total_actual)
    ) |> 
    select(-total_actual) |> 
    unnest_wider(p) |> 
    arrange(p.value)
  
  list(
    rounds = round_streak_prop,
    series = series_outcome_prop
  )
}

cod_streaks_naive_res <- summarize_cod_streaks(p = 0.5)
```

Table \ref{tbl:cod-prob-series-lasting-r-rounds} shows the expected series lasting $r$ rounds, $\hat{\Phi}_0(r)$ (under the assumption $\phi_0 = 0.5$), for $s = 11$, along with the observed proportions, $\Phi(r)$, in CoD SnD.

```{=tex}
\begin{longtable}{rrrr}
\caption{The expected proportion of series lasting $r$ rounds ($\hat{\Phi}_0(r)$) in a best-of-11 format, wehre $r \in R = [6, 7, 8, 9, 10, 11]$ under the assumption that each team has a constant round win probability $\phi_0 = 0.5$. The observed frequencies for CoD SnD are shown as a count $N(r)$ and as a proportion $\Phi(r)$ of all series ($\sum^R N(r)$).}\label{tbl:cod-prob-series-lasting-r-rounds} \\
\toprule
$r$ & $\hat{\Phi}_0(r)$ & $\Phi(r)$ & $N(r)$ \\ 
\midrule
6 & $3.1\%$ & $4.7\%$ & 40 \\ 
7 & $9.4\%$ & $11.9\%$ & 101 \\ 
8 & $16.4\%$ & $16.5\%$ & 141 \\ 
9 & $21.9\%$ & $21.7\%$ & 185 \\ 
10 & $24.6\%$ & $21.5\%$ & 183 \\ 
11 & $24.6\%$ & $23.7\%$ & 202 \\ 
\bottomrule
\end{longtable}
```
```{r}
#| label: cod_series_outcomes_naive_chi
generate_chi_label <- function(statistic, p.value) {
  sprintf('%.1f (%s)', statistic, ifelse(p.value <= 0.01, '<=0.01', as.character(round(p.value, 2))))
}

perform_series_chi_test <- function(series) {
  chisq.test(
    series$n_actual, 
    p = series$prop_expected
  ) |> 
    broom::tidy()
}

cod_series_outcomes_naive_chi <- cod_streaks_naive_res$series |> 
  perform_series_chi_test()
```

```{r}
#| label: cod-alternative-to-p=0.5-method-prep
min_p1 <- 0.5
max_p1 <- 0.7
interval_p1 <- 0.0025
cod_ps <- tibble(p = seq(min_p1, max_p1, by = 0.0025))
```

```{r}
#| label: cod-alternative-to-p=0.5-method-1
## p. 365 on https://math.mit.edu/classes/18.095/2016IAP/lec9/Sports_Mosteller1952_WorldSeries.pdf
cod_prob_of_series_lasting_r_rounds <- function(r, p) {
  prob_of_series_lasting_r_rounds(r = r, p = p, s = 11)
}

theoretical_cod_series_length <- function(p) {
  6 * cod_prob_of_series_lasting_r_rounds(r = 6, p = p) +
    7 * cod_prob_of_series_lasting_r_rounds(r = 7, p = p) +
    8 * cod_prob_of_series_lasting_r_rounds(r = 8, p = p) +
    9 * cod_prob_of_series_lasting_r_rounds(r = 9, p = p) +
    10 * cod_prob_of_series_lasting_r_rounds(r = 10, p = p) +
    11 * cod_prob_of_series_lasting_r_rounds(r = 11, p = p)
}

cod_rounds_per_series <- cod_streaks_naive_res$series |>
  summarize(
    actual = sum(n_rounds * prop_actual),
    expected = sum(n_rounds * prop_expected)
  )

cod_theoretical_series_lengths1 <- cod_ps |>
  mutate(
    theoretical_series_length = map_dbl(p, theoretical_cod_series_length),
    diff = theoretical_series_length - cod_rounds_per_series$actual
  )

cod_theoretical_p1 <- cod_theoretical_series_lengths1 |>
  slice_min(abs(diff), n = 1) |>
  pull(p)
```

```{r}
#| label: cod-alternative-to-p=0.5-method-2
pluck_cod_n <- function(.n_rounds) {
  cod_streaks_naive_res$series |>
    filter(n_rounds == .n_rounds) |>
    pull(n_actual)
}

cod_n6 <- pluck_cod_n(6)
cod_n7 <- pluck_cod_n(7)
cod_n8 <- pluck_cod_n(8)
cod_n9 <- pluck_cod_n(9)
cod_n10 <- pluck_cod_n(10)
cod_n11 <- pluck_cod_n(11)

## This adjustment is something that is not done in the paper. I do it here to reduce
##   the magnitude of the exponents.
cod_pm <- pmin(cod_n6, cod_n7, cod_n8, cod_n9, cod_n10, cod_n11)
cod_n6adj <- round(10 * cod_n6 / cod_pm)
cod_n7adj <- round(10 * cod_n7 / cod_pm)
cod_n8adj <- round(10 * cod_n8 / cod_pm)
cod_n9adj <- round(10 * cod_n9 / cod_pm)
cod_n10adj <- round(10 * cod_n10 / cod_pm)
cod_n11adj <- round(10 * cod_n11 / cod_pm)

maximize_cod_series_p <- function(p) {
  cod_prob_of_series_lasting_r_rounds(r = 6, p = p)^cod_n6adj *
    cod_prob_of_series_lasting_r_rounds(r = 7, p = p)^cod_n7adj *
    cod_prob_of_series_lasting_r_rounds(r = 8, p = p)^cod_n8adj *
    cod_prob_of_series_lasting_r_rounds(r = 9, p = p)^cod_n9adj *
    cod_prob_of_series_lasting_r_rounds(r = 10, p = p)^cod_n10adj *
    cod_prob_of_series_lasting_r_rounds(r = 11, p = p)^cod_n11adj
}

cod_theoretical_series_lengths2 <- cod_ps |>
  mutate(
    theoretical_series_length = map_dbl(p, maximize_cod_series_p)
  )

cod_theoretical_p2 <- cod_theoretical_series_lengths2 |>
  slice_max(theoretical_series_length, n = 1) |>
  pull(p)
```

```{r}
#| label: cod-alternative-to-p=0.5-method-3
summarize_cod_series_chi <- function(p) {
  summarize_cod_streaks(p) |> 
    pluck('series') |> 
    perform_series_chi_test()
}

cod_theoretical_series_lengths3 <- cod_ps |> 
  filter(p >= 0.56, p < 0.585) |> 
  mutate(
    chi_squ = map_dbl(
      p,
      ~summarize_cod_series_chi(.x) |> 
        pluck('statistic')
    )
  )

cod_theoretical_p3 <- cod_theoretical_series_lengths3 |> 
  slice_min(chi_squ, n = 1) |> 
  pull(p)
```

```{r}
#| label: cod-alternatives-to-p=0.5
cod_streaks_other_res <- tibble(
  p = c(0.5, cod_theoretical_p1, cod_theoretical_p2, cod_theoretical_p3),
  idx = 0L:3L,
  name = c('0. Naive', '1. Method of moments', '2. Maximum likelihood', '3. Minimum Chi-square')
) |> 
  mutate(
    series_streaks = map(
      p,
      ~summarize_cod_streaks(.x) |> 
        pluck('series') 
    ),
    chi_squ = map(
      series_streaks,
      ~.x |> 
        perform_series_chi_test() |> 
        select(statistic, p.value)
    )
  )
```

Table \ref{tbl:mosteller-methods-results} shows the alternate values for the constant round win probability that I find when applying the three methods suggested by Mosteller [-@mosteller1952]. Each is approximately or equal to 0.575, and, when applying Equation \ref{eq:chi-squ}, each results in a $\chi^2$ value for which I cannot reject the constant probability null hypothesis.

```{=tex}
\begin{longtable}[]{@{}lrr@{}}
\caption{Alternate estimates of the constant probability ($\phi$) for winning a given round in a CoD SnD, applying the three methods suggested by Mosteller (1952), in addition to the naive ($\phi_0 = 0.5$).}\label{tbl:mosteller-methods-results} \\
\toprule()
Method & $\phi$ & $\chi^2$ (p-value) \\
\midrule()
\endfirsthead
\toprule()
Method & $\phi(r)$ & $\chi^2$ (p-value) \\
\midrule()
\endhead
0. Naive & 0.5000 & 16.0 (\textless=0.01) \\
1. Method of moments & 0.5725 & 3.6 (0.6) \\
2. Maximum likelihood & 0.5750 & 3.5 (0.62) \\
3. Minimum ($\chi^2$) & 0.5775 & 3.5 (0.62) \\
\bottomrule()
\end{longtable}
```
Table \ref{tbl:expected-series-lengths-alternative-ps} shows the new $\hat{\Phi}(r)$ when re-applying Equation \ref{eq:series-length} for the maximum likelihood estimate $\phi_2 = 0.575$, resulting in a new set of expected proportions of series lasting $r$ rounds $\hat{\Phi}_2(r)$.[^14] I observe that $\hat{\Phi}_2(r)$ is larger than $\hat{\Phi}_0(r)$ for $r \in [6, 7]$, more closely matching $\Phi(r)$. $\hat{\Phi}_2(r)$ is also closer to the observed $\Phi(r)$ for $r \in [9, 10]$, although not for $r \in [8, 11]$.

[^14]: The method of moments and minimum $\chi^2$ estimates for $\phi$ are omitted simply because the results would be nearly identical to those for the maximum likelihood estimate of $\phi$ (since they are all $\approx 0.575$).

```{=tex}
\begin{longtable}[]{@{}rrrr@{}}
\caption{The observed proportion of series $\Phi(r)$ ending in $r$ rounds in CoD SnD's best-of-11 format, compared to the expected proportion $\hat{\Phi}_0(r)$ the naive assumption $\phi_0 = 0.5$ and the expected proportion $\hat{\Phi}_2(r)$ under the maximum likelihood estimate $\phi_2 = 0.575$ for constant round win probability.}\label{tbl:expected-series-lengths-alternative-ps} \\
\toprule()
$r$ & $\hat{\Phi}_0(r)$ = 0.5 & $\hat{\Phi}_2(r)$ = 0.575 & $\Phi(r)$ \\
\midrule()
\endhead
6 & 3.1\% & 4.2\% & 4.7\% \\
7 & 9.4\% & 11.2\% & 11.9\% \\
8 & 16.4\% & 17.8\% & 16.5\% \\
9 & 21.9\% & 21.8\% & 21.7\% \\
10 & 24.6\% & 23.0\% & 21.5\% \\
11 & 24.6\% & 22.0\% & 23.7\% \\
\bottomrule()
\end{longtable}
```
Observing that $\hat{\Phi}_2(r)$ reasonably matches $\Phi(r)$ (especially in comparison to $\hat{\Phi}_0(r)$), along with the null hypothesis rejection shown in Table \ref{tbl:mosteller-methods-results}, it is fair to conclude that the constant round win probability assumption can be valid in CoD SnD series with the appropriate choice of $\phi$ ($\approx 0.575$).

## Momentum {#sec:results-momentum}

```{r}
#| label: cod_round_win_prop_after_k_wins
cod_round_streaks <- cod_rounds |> 
  group_by(series_id, team) |> 
  mutate(
    won_prior_round1 = lag(win_round, n = 1, default = NA),
    won_prior_round2 = lag(win_round, n = 2, default = NA),
    won_prior_round3 = lag(win_round, n = 3, default = NA),
    won_prior_round4 = lag(win_round, n = 4, default = NA),
    won_prior_round5 = lag(win_round, n = 5, default = NA)
  ) |> 
  ungroup() |>
  select(
    series_id,
    team,
    is_offense,
    round,
    n_rounds,
    win_series,
    win_round,
    starts_with('won_prior_round')
  )

postprocess_round_streaks <- function(k, probs_nx_k, ...) {
  
  cols <- sprintf('won_prior_round%d', 2:k)
  col_syms <- syms(cols)
  cod_round_streaks_after_x <- cod_round_streaks |> 
    drop_na(!!!col_syms) |> 
    count(n_rounds, win_series, win_round, won_prior_round1, !!!col_syms, sort = TRUE)
  
  cod_round_win_prop_after_z <- cod_round_streaks_after_x |> 
    filter(won_prior_round1, !!!col_syms)
  
  suppressMessages(
    cod_round_win_prop_after_z_with_probs <- cod_round_win_prop_after_z |> 
      group_by(win_series, n_rounds) |> 
      mutate(
        total = sum(n),
        prop = n / total
      ) |> 
      ungroup() |> 
      select(n_rounds, win_round, win_series, n, total, prop) |> 
      arrange(n_rounds, win_round) |> 
      inner_join(
        probs_nx_k
      )
  )
  
  suppressMessages(
    full_join(
      cod_round_win_prop_after_z_with_probs |> 
        nest(data = -c(n_rounds, win_series, win_round)) |> 
        mutate(
          ## TODO: Vectorize this.
          binom_p_value = map_dbl(
            data, 
            ~binom.test(.x$n, .x$total, .x$notional_prop, alternative = 'greater') |> 
              broom::tidy() |>
              pull(p.value)
          ),
          binom_is_signif = binom_p_value <= 0.05
        ) |> 
        unnest(data),
      cod_round_win_prop_after_z_with_probs |> 
        select(n_rounds, win_round, win_series, n, total, prop, notional_prop) |> 
        mutate(
          notional_n = as.integer(n * notional_prop / prop),
          notional_total = as.integer(total * notional_prop / prop), 
          compared_p_value = vectorized_prop_test(n, total, notional_n, notional_total)$p.value,
          compared_is_signif = compared_p_value <= 0.05
        )
    )
  )
}

summarize_cod_win_prop_after_k_wins <- function(k) {
  probs_nx_k <- crossing(
    n_rounds = 7L:11L,
    win_series = c(TRUE, FALSE),
    win_round = c(TRUE, FALSE)
  ) |> 
    mutate(
      is_valid = case_when(
        win_series ~ TRUE,
        (n_rounds - !!k - 6L) >= 0L ~ TRUE,
        TRUE ~ FALSE
      )
    ) |> 
    filter(is_valid) |> 
    select(-is_valid) |> 
    mutate(
      naive_prop = ifelse(win_series, 6L / n_rounds, (n_rounds - 6L) / n_rounds),
      notional_prop = (ifelse(win_series, 6L, n_rounds - 6L) - k) / (n_rounds - k),
      across(c(naive_prop, notional_prop), ~ifelse(win_round, .x, 1 - .x)),
      ms_prop = map2_dbl(
        n_rounds, naive_prop, 
        ~simulate_post_streak_prob(n = ..1, k = !!k, p = ..2)
      ),
      diff_prop = notional_prop - ms_prop
    ) |> 
    filter(notional_prop > 0, notional_prop < 1)
  
  postprocess_round_streaks(
    k = k,
    probs_nx_k = probs_nx_k
  )
}

cod_round_win_prop_after_k_wins <- tibble(win_streak = 3L) |>
  mutate(
    data = map(win_streak, summarize_cod_win_prop_after_k_wins)
  ) |>
  unnest(data)
```

```{r}
#| label: cod_round_win_prop_after_k_wins-table
cod_round_win_prop_after_k_wins |> 
  mutate(
    across(
      matches('p_value'), 
      ~case_when(
        .x <= 0.01 ~ '<=0.01', 
        round(.x, 2) == 1 ~ '1.00',
        TRUE ~ as.character(round(.x, 2))
      )
    ),
    prop_lab = scales::percent(prop, accuracy = 0.1),
    binom_lab = sprintf('%.1f%% (%s)', round(100 * notional_prop, 1), binom_p_value),
    compared_lab = scales::percent(ms_prop, accuracy = 0.1),
    diff_lab = sprintf('%.1f%% (%s)', round(100 * diff_prop, 1), compared_p_value)
  ) |>
  arrange(win_streak, n_rounds, win_series) |> 
  transmute(
    win_series,
    win_round,
    n_rounds,
    total,
    prop_lab,
    binom_lab,
    compared_lab,
    diff_lab
  ) |>
  group_split(win_series, win_round) |> 
  walk(
    function(df) {
      message(sprintf('win_round=%s, win_series=%s', df$win_round[[1]], df$win_series[[1]]))
      df <- df |> 
        select(
          -c(win_series, win_round)
        ) |> 
        gt::gt() |> 
        gt::cols_label(
          # win_streak = 'Streak',
          n_rounds = 'r',
          total = 'N',
          prop_lab = 'O',
          binom_lab = 'a',
          compared_lab = 'b',
          diff_lab = 'c'
        ) |> 
        gt::as_latex() |> 
        cat()
    }
  )

```

Given that people typically perceive streaks as beginning after the third success (or failure) at minimum [@carlson2007], I focus on streaks of three round wins.[^15] Table \ref{tbl:cod-pw3r-pl3r} shows $P^{w,kr}$ and $P^{l,kr}$ for round win rate and loss rate following $k = 3$ round win streaks respectively.

[^15]: Three happens to also be a reasonable number for series that lasts at maximum 11 rounds.

First,

```{=tex}
\begin{longtable}{rrrrrrr}
\caption{Observed count and proportion of round wins immediately following round win streak of $k=3$, $N^{w|kr}$ and $P^{w|kr}$ respectively, in series lasting $r$ rounds. Additionally, notional expected proportion, $\hat{P}^{w|kr}_0$ and binomial test p-value, assuming notional round probability $p^{w|kr}$ and using observed counts; MS expected proportion $\hat{P}^{w|kr}_{MS}$; and $\hat{D}^{w|kr} = \hat{P}^{w|kr}_{MS} - \hat{P}^{w|kr}_0$ and proportion test p-value. Fields presented in groups, split by whether the team won the round immediately following the 3-round win streak, and whether the team won the series. The post-streak loss analogues are presented as $N^{\ell|kr}$, $P^{\ell|kr}$, $\hat{P}^{\ell|kr}_0$, $\hat{P}^{\ell|kr}_{MS}$, and $\hat{D}^{\ell|kr}$.}
\label{tbl:cod-pw3r-pl3r} \\
\toprule
\multicolumn{6}{c}{\text{win series, win after 3-round win streak}} \\
\midrule
$r$ & $N^{w|kr}$ & $P^{w|kr}$ & $\hat{P}^{w|kr}_0$ ($p$-value) & $\hat{P}^{w|kr}_{MS}$ & $\hat{D}^{w|kr}$ ($p$-value) \\ 
\midrule
7 & 209 & 74.6\% & 75.0\% (0.58) & 75.7\% & -0.7\% (0.94) \\ 
8 & 209 & 62.2\% & 60.0\% (0.28) & 61.9\% & -1.9\% (1.00) \\ 
9 & 193 & 51.8\% & 50.0\% (0.33) & 52.7\% & -2.7\% (0.97) \\ 
10 & 151 & 43.7\% & 42.9\% (0.45) & 44.7\% & -1.8\% (0.94) \\ 
11 & 150 & 40.0\% & 37.5\% (0.29) & 38.8\% & -1.3\% (1.00) \\ 
\toprule
\toprule
\multicolumn{6}{c}{\text{lose series, win after 3-round win streak}} \\
\midrule
$r$ & $N^{w|kr}$ & $P^{w|kr}$ & $\hat{P}^{w|kr}_0$ ($p$-value) & $\hat{P}^{w|kr}_{MS}$ & $\hat{D}^{w|kr}$ ($p$-value) \\ 
\midrule
10 & 60 & 13.3\% & 14.3\% (0.64) & 26.7\% & -12.4\% (1.00) \\ 
11 & 129 & 24.0\% & 25.0\% (0.63) & 30.8\% & -5.8\% (0.98) \\ 
\toprule
\toprule
\multicolumn{6}{c}{\text{win series, lose after 3-round win streak}} \\
\midrule
$r$ & $N^{\ell|kr}$ & $P^{\ell|kr}$ & $\hat{P}^{\ell|kr}_0$ ($p$-value) & $\hat{P}^{\ell|kr}_{MS}$ & $\hat{D}^{\ell|kr}$ ($p$-value) \\ 
\midrule
7 & 209 & 25.4\% & 25.0\% (0.48) & 6.4\% & 18.6\% (0.98) \\ 
8 & 209 & 37.8\% & 40.0\% (0.76) & 14.7\% & 25.3\% (0.96) \\ 
9 & 193 & 48.2\% & 50.0\% (0.72) & 22.2\% & 27.8\% (0.97) \\ 
10 & 151 & 56.3\% & 57.1\% (0.62) & 26.7\% & 30.5\% (0.99) \\ 
11 & 150 & 60.0\% & 62.5\% (0.76) & 30.8\% & 31.7\% (0.95) \\ 
\toprule
\toprule
\multicolumn{6}{c}{\text{lose series, lose after 3-round win streak}} \\
\midrule
$r$ & $N^{\ell|kr}$ & $P^{\ell|kr}$ & $\hat{P}^{\ell|kr}_0$ ($p$-value) & $\hat{P}^{\ell|kr}_{MS}$ & $\hat{D}^{\ell|kr}$ ($p$-value) \\ 
\midrule
10 & 60 & 86.7\% & 85.7\% (0.51) & 44.7\% & 41.1\% (1.00) \\ 
11 & 129 & 76.0\% & 75.0\% (0.45) & 38.8\% & 36.2\% (0.95) \\ 
\bottomrule
\end{longtable}
```
# References {.unnumbered}

::: {#refs}
:::
